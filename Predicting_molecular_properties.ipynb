<style>
    div.output_area{
        max-height:600px;
        overflow:scroll;
    }
</style>
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting scalar coupling constant between two atoms in different organic molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/dionizije/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import inspect\n",
    "from sklearn.pipeline import Pipeline\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import regularizers\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from numpy.random import seed\n",
    "import keras.backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats as sp\n",
    "from sklearn.externals.joblib import parallel_backend\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from keras import optimizers\n",
    "import random\n",
    "from biopandas.mol2 import PandasMol2\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real\n",
    "from skopt.space import Integer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from skopt import gp_minimize\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.utils import use_named_args\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".nbviewer div.output_area {\n",
       "  overflow-y: auto;\n",
       "  max-height: 500px;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".nbviewer div.output_area {\n",
    "  overflow-y: auto;\n",
    "  max-height: 500px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing directory and setting seed for random operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seed(0)\n",
    "os.chdir('/home/dionizije/Desktop/Code/Predicting molecular properties')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the train set and structure of the molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', index_col = 'id') \n",
    "structures = pd.read_csv('structures.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.8076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.2570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.2548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.2543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.8074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       molecule_name  atom_index_0  atom_index_1  type  \\\n",
       "id                                                       \n",
       "0   dsgdb9nsd_000001             1             0  1JHC   \n",
       "1   dsgdb9nsd_000001             1             2  2JHH   \n",
       "2   dsgdb9nsd_000001             1             3  2JHH   \n",
       "3   dsgdb9nsd_000001             1             4  2JHH   \n",
       "4   dsgdb9nsd_000001             2             0  1JHC   \n",
       "\n",
       "    scalar_coupling_constant  \n",
       "id                            \n",
       "0                    84.8076  \n",
       "1                   -11.2570  \n",
       "2                   -11.2548  \n",
       "3                   -11.2543  \n",
       "4                    84.8074  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5) #Data provided in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index</th>\n",
       "      <th>atom</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>3</td>\n",
       "      <td>H</td>\n",
       "      <td>-0.540815</td>\n",
       "      <td>1.447527</td>\n",
       "      <td>-0.876644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>4</td>\n",
       "      <td>H</td>\n",
       "      <td>-0.523814</td>\n",
       "      <td>1.437933</td>\n",
       "      <td>0.906397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      molecule_name  atom_index atom         x         y         z\n",
       "0  dsgdb9nsd_000001           0    C -0.012698  1.085804  0.008001\n",
       "1  dsgdb9nsd_000001           1    H  0.002150 -0.006031  0.001976\n",
       "2  dsgdb9nsd_000001           2    H  1.011731  1.463751  0.000277\n",
       "3  dsgdb9nsd_000001           3    H -0.540815  1.447527 -0.876644\n",
       "4  dsgdb9nsd_000001           4    H -0.523814  1.437933  0.906397"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures.head(5) #Data provided in the structure files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training set = 0\n",
      "Missing values in structures = 0\n"
     ]
    }
   ],
   "source": [
    "print('Missing values in training set = {}'.format(train.isnull().sum().sum())) \n",
    "print('Missing values in structures = {}'.format(structures.isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks for missing data in the structures and training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of molecules in the training set molecules = 85003\n",
      "Unique scalar coupling types = ['1JHC' '2JHH' '1JHN' '2JHN' '2JHC' '3JHH' '3JHC' '3JHN']\n"
     ]
    }
   ],
   "source": [
    "print('Number of molecules in the training set molecules = {}'.format(train.molecule_name.nunique()))\n",
    "print('Unique scalar coupling types = {}'.format(train.type.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of the scalar coupling constant in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def distplot_with_hue(df, x, hue, hist=True, kde=True):\n",
    "    _, bins = np.histogram(df[x])\n",
    "    g = sns.FacetGrid(df, hue=hue)\n",
    "    g = g.map(sns.distplot, x, bins=bins, hist=hist, kde=kde)\n",
    "    g.ax.legend(loc=2, bbox_to_anchor=(1.05, 1))\n",
    "    \n",
    "distplot_with_hue(train, 'scalar_coupling_constant', 'type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of the scalar coupling constant by molecules types -> some values are distinct while others are overlapped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features from biopandas module --> Atom hybridization, distances, ligand types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def mol_2_files():\n",
    "    \"\"\"Features from biopandas from mol2/xyz structure files\"\"\"\n",
    "    files = []\n",
    "    for file in os.listdir('/home/dionizije/Desktop/Code/Predicting molecular properties/mol'):\n",
    "        if file.endswith('.mol2'):\n",
    "            files.append(file)\n",
    "            \n",
    "    molecules = []\n",
    "    for molecule in files:\n",
    "        try: #try statement, because there is a .mol2 file which is not a molecule and stops execution\n",
    "            mol2_object = PandasMol2().read_mol2(path = '/home/dionizije/Desktop/Code/Predicting molecular properties/mol/' + molecule)\n",
    "            molecule_name = molecule.rsplit(\".\", 1)[0] #gets rid of the extension\n",
    "            molecule_name_column = [molecule_name] * int(len(mol2_object.df)) #list for molecule name column\n",
    "            df_object = mol2_object.df #gets dataframe object\n",
    "            df_object['molecule_name'] = molecule_name_column\n",
    "            distances = mol2_object.distance() #distance from 0,0,0 reference point\n",
    "            df_object['dist_from_refp'] = distances \n",
    "            df_object['atom_id'] = df_object['atom_id'] - 1 #changing indices to start from 0\n",
    "            df_object.drop(['x', 'y', 'z'], axis = 1, inplace = True) #drops coordinates --> already in structures file\n",
    "            df_object = df_object.rename(columns = {'atom_id': 'atom_index'})\n",
    "            molecules.append(df_object) \n",
    "        except:\n",
    "            pass\n",
    "    df_molecules = pd.concat(molecules)\n",
    "    return df_molecules\n",
    "\n",
    "df_molecules = mol_2_files() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atom_index</th>\n",
       "      <th>atom_name</th>\n",
       "      <th>atom_type</th>\n",
       "      <th>subst_id</th>\n",
       "      <th>subst_name</th>\n",
       "      <th>charge</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>dist_from_refp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>C.3</td>\n",
       "      <td>1</td>\n",
       "      <td>LIG1</td>\n",
       "      <td>-0.0649</td>\n",
       "      <td>dsgdb9nsd_118835</td>\n",
       "      <td>1.565290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>C.3</td>\n",
       "      <td>1</td>\n",
       "      <td>LIG1</td>\n",
       "      <td>-0.0504</td>\n",
       "      <td>dsgdb9nsd_118835</td>\n",
       "      <td>0.306451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>C.3</td>\n",
       "      <td>1</td>\n",
       "      <td>LIG1</td>\n",
       "      <td>-0.0097</td>\n",
       "      <td>dsgdb9nsd_118835</td>\n",
       "      <td>1.522293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>C.3</td>\n",
       "      <td>1</td>\n",
       "      <td>LIG1</td>\n",
       "      <td>-0.0182</td>\n",
       "      <td>dsgdb9nsd_118835</td>\n",
       "      <td>2.475827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>C</td>\n",
       "      <td>C.3</td>\n",
       "      <td>1</td>\n",
       "      <td>LIG1</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>dsgdb9nsd_118835</td>\n",
       "      <td>2.570540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   atom_index atom_name atom_type  subst_id subst_name  charge  \\\n",
       "0           0         C       C.3         1       LIG1 -0.0649   \n",
       "1           1         C       C.3         1       LIG1 -0.0504   \n",
       "2           2         C       C.3         1       LIG1 -0.0097   \n",
       "3           3         C       C.3         1       LIG1 -0.0182   \n",
       "4           4         C       C.3         1       LIG1  0.0714   \n",
       "\n",
       "      molecule_name  dist_from_refp  \n",
       "0  dsgdb9nsd_118835        1.565290  \n",
       "1  dsgdb9nsd_118835        0.306451  \n",
       "2  dsgdb9nsd_118835        1.522293  \n",
       "3  dsgdb9nsd_118835        2.475827  \n",
       "4  dsgdb9nsd_118835        2.570540  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_molecules.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_molecules.to_csv('/home/dionizije/Desktop/Code/Predicting molecular properties/Features/df_molecules.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving bigger dataframes to disk in case of memory crashes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging features from df_molecules to structure files and adding structure information to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def merge_mol2():\n",
    "    \"\"\"Merges molecules data from biopandas to structures file\"\"\"\n",
    "    data = pd.merge(structures, df_molecules, how = 'left',\n",
    "                    right_on = ['molecule_name', 'atom_index'],\n",
    "                    left_on = ['molecule_name', 'atom_index'])\n",
    "    data = data.drop(['atom_name', 'subst_id'], axis = 1)\n",
    "    return data\n",
    "\n",
    "structures = merge_mol2()\n",
    "del(df_molecules) #del for releasing from memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index</th>\n",
       "      <th>atom</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>atom_type</th>\n",
       "      <th>subst_name</th>\n",
       "      <th>charge</th>\n",
       "      <th>dist_from_refp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>C.3</td>\n",
       "      <td>LIG1</td>\n",
       "      <td>-0.0776</td>\n",
       "      <td>1.085904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>H</td>\n",
       "      <td>LIG1</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.006696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>H</td>\n",
       "      <td>LIG1</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>1.779395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>3</td>\n",
       "      <td>H</td>\n",
       "      <td>-0.540815</td>\n",
       "      <td>1.447527</td>\n",
       "      <td>-0.876644</td>\n",
       "      <td>H</td>\n",
       "      <td>LIG1</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>1.776555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>4</td>\n",
       "      <td>H</td>\n",
       "      <td>-0.523814</td>\n",
       "      <td>1.437933</td>\n",
       "      <td>0.906397</td>\n",
       "      <td>H</td>\n",
       "      <td>LIG1</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>1.778619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      molecule_name  atom_index atom         x         y         z atom_type  \\\n",
       "0  dsgdb9nsd_000001           0    C -0.012698  1.085804  0.008001       C.3   \n",
       "1  dsgdb9nsd_000001           1    H  0.002150 -0.006031  0.001976         H   \n",
       "2  dsgdb9nsd_000001           2    H  1.011731  1.463751  0.000277         H   \n",
       "3  dsgdb9nsd_000001           3    H -0.540815  1.447527 -0.876644         H   \n",
       "4  dsgdb9nsd_000001           4    H -0.523814  1.437933  0.906397         H   \n",
       "\n",
       "  subst_name  charge  dist_from_refp  \n",
       "0       LIG1 -0.0776        1.085904  \n",
       "1       LIG1  0.0194        0.006696  \n",
       "2       LIG1  0.0194        1.779395  \n",
       "3       LIG1  0.0194        1.776555  \n",
       "4       LIG1  0.0194        1.778619  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def merge_structures(data, atom_index):\n",
    "    \"\"\"Merges atom data from structures to atom data in the training sets\"\"\"\n",
    "    data = pd.merge(data, structures, how = 'left',\n",
    "                    left_on = ['molecule_name', 'atom_index_{}'.format(atom_index)],\n",
    "                    right_on = ['molecule_name', 'atom_index'])\n",
    "    data = data.drop('atom_index', axis = 1)\n",
    "    data = data.rename(columns = {'atom': 'atom_{}'.format(atom_index),\n",
    "                                  'x': 'x_{}'.format(atom_index),\n",
    "                                  'y': 'y_{}'.format(atom_index),\n",
    "                                  'z': 'z_{}'.format(atom_index)})\n",
    "    return data\n",
    "\n",
    "train = merge_structures(train, 0)\n",
    "train = merge_structures(train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "      <th>atom_0</th>\n",
       "      <th>x_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>z_0</th>\n",
       "      <th>atom_type_x</th>\n",
       "      <th>...</th>\n",
       "      <th>charge_x</th>\n",
       "      <th>dist_from_refp_x</th>\n",
       "      <th>atom_1</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>atom_type_y</th>\n",
       "      <th>subst_name_y</th>\n",
       "      <th>charge_y</th>\n",
       "      <th>dist_from_refp_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.8076</td>\n",
       "      <td>H</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>C.3</td>\n",
       "      <td>LIG1</td>\n",
       "      <td>-0.0776</td>\n",
       "      <td>1.085904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.2570</td>\n",
       "      <td>H</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>H</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>H</td>\n",
       "      <td>LIG1</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>1.779395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.2548</td>\n",
       "      <td>H</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>H</td>\n",
       "      <td>-0.540815</td>\n",
       "      <td>1.447527</td>\n",
       "      <td>-0.876644</td>\n",
       "      <td>H</td>\n",
       "      <td>LIG1</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>1.776555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.2543</td>\n",
       "      <td>H</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>H</td>\n",
       "      <td>-0.523814</td>\n",
       "      <td>1.437933</td>\n",
       "      <td>0.906397</td>\n",
       "      <td>H</td>\n",
       "      <td>LIG1</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>1.778619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.8074</td>\n",
       "      <td>H</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>1.779395</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>C.3</td>\n",
       "      <td>LIG1</td>\n",
       "      <td>-0.0776</td>\n",
       "      <td>1.085904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      molecule_name  atom_index_0  atom_index_1  type  \\\n",
       "0  dsgdb9nsd_000001             1             0  1JHC   \n",
       "1  dsgdb9nsd_000001             1             2  2JHH   \n",
       "2  dsgdb9nsd_000001             1             3  2JHH   \n",
       "3  dsgdb9nsd_000001             1             4  2JHH   \n",
       "4  dsgdb9nsd_000001             2             0  1JHC   \n",
       "\n",
       "   scalar_coupling_constant atom_0       x_0       y_0       z_0 atom_type_x  \\\n",
       "0                   84.8076      H  0.002150 -0.006031  0.001976           H   \n",
       "1                  -11.2570      H  0.002150 -0.006031  0.001976           H   \n",
       "2                  -11.2548      H  0.002150 -0.006031  0.001976           H   \n",
       "3                  -11.2543      H  0.002150 -0.006031  0.001976           H   \n",
       "4                   84.8074      H  1.011731  1.463751  0.000277           H   \n",
       "\n",
       "   ... charge_x  dist_from_refp_x  atom_1       x_1       y_1       z_1  \\\n",
       "0  ...   0.0194          0.006696       C -0.012698  1.085804  0.008001   \n",
       "1  ...   0.0194          0.006696       H  1.011731  1.463751  0.000277   \n",
       "2  ...   0.0194          0.006696       H -0.540815  1.447527 -0.876644   \n",
       "3  ...   0.0194          0.006696       H -0.523814  1.437933  0.906397   \n",
       "4  ...   0.0194          1.779395       C -0.012698  1.085804  0.008001   \n",
       "\n",
       "   atom_type_y subst_name_y charge_y  dist_from_refp_y  \n",
       "0          C.3         LIG1  -0.0776          1.085904  \n",
       "1            H         LIG1   0.0194          1.779395  \n",
       "2            H         LIG1   0.0194          1.776555  \n",
       "3            H         LIG1   0.0194          1.778619  \n",
       "4          C.3         LIG1  -0.0776          1.085904  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.to_csv('/home/dionizije/Desktop/Code/Predicting molecular properties/Features/train_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "del(structures)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function for adding additional features, and splitting the training set to features and target\n",
    "Added features are distance between coupling atoms, dipole moments, atomic radius, electronegativity, angles between point vectors.\n",
    "Categorical variables are one hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def preprocessing_features(data):\n",
    "    \n",
    "    #Distance between coupling atoms\n",
    "    data['dist_coupling_atoms'] = ((data['x_1'] - data['x_0'])**2 + (data['y_1'] - data['y_0'])**2 + (data['z_1'] - data['z_0'])**2)**1/2\n",
    "    \n",
    "    #adding dipole moments\n",
    "    dipole_moments = pd.read_csv('dipole_moments.csv')\n",
    "    data = pd.merge(data, dipole_moments, how = 'inner', left_on = ['molecule_name'],\n",
    "                     right_on = ['molecule_name'])\n",
    "    data.rename(columns  = {'X_x': 'X_dipole', 'Y_x': 'Y_dipole', 'Z_x': 'Z_dipole'}, inplace = True)\n",
    "    \n",
    "    #adding atomic radius\n",
    "    atomic_radius = pd.DataFrame({'radius' : [67, 53, 56, 48, 42]},\n",
    "                             index = ['C', 'H', 'N', 'O', 'F'])\n",
    "    \n",
    "    data = data.merge(atomic_radius, left_on = ['atom_0'], right_on = atomic_radius.index)\n",
    "    data = data.rename(columns = {'atomic_radius' : 'radius_atom_0'})\n",
    "    \n",
    "    #adding atomic radius\n",
    "    data = data.merge(atomic_radius, left_on = ['atom_1'], right_on = atomic_radius.index)\n",
    "    data = data.rename(columns = {'atomic_radius' : 'radius_atom_1'})\n",
    "    \n",
    "    #adding electronegativity\n",
    "    electronegativity = pd.DataFrame({'electronegativity' : [2.55, 2.20, 3.04, 3.44, 3.98]},\n",
    "                                  index = ['C', 'H', 'N', 'O', 'F'])\n",
    "    \n",
    "    data = data.join(electronegativity, how = 'left', on = ['atom_0'])\n",
    "    data = data.rename(columns = {'electronegativity' : 'electronegativity_atom_0'})\n",
    "    \n",
    "    #adding electronegativity\n",
    "    data = data.join(electronegativity, how = 'left', on = ['atom_1'])\n",
    "    data = data.rename(columns = {'electronegativity' : 'electronegativity_atom_1'})\n",
    "    \n",
    "    \n",
    "    data.drop(columns = ['atom_index_0', 'atom_index_1', 'atom_0', 'atom_1'], inplace = True)\n",
    "    \n",
    "    #dummies and dropping columns\n",
    "    X = data.drop(columns = 'molecule_name')\n",
    "    X = pd.get_dummies(X, columns = ['type', 'atom_type_x', 'atom_type_y', 'subst_name_x',\n",
    "                                     'subst_name_y'], drop_first = True)\n",
    "    y = X['scalar_coupling_constant']\n",
    "    X.drop(columns = 'scalar_coupling_constant', inplace = True)\n",
    "    \n",
    "    def calculate_angles(X):\n",
    "        \"Calculates angles between two unit vectors\"\"\"\n",
    "        def unit_vector(vector):\n",
    "            \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "            return vector / np.linalg.norm(vector)\n",
    "    \n",
    "        def angle_btw_vectors(v1, v2):\n",
    "            \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'::\"\"\"\n",
    "            v1_u = unit_vector(v1)\n",
    "            v2_u = unit_vector(v2)\n",
    "            return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "    \n",
    "        vectors_0 = []\n",
    "        for i in range(0, len(X)):\n",
    "            x = X['x_0'].iloc[i]\n",
    "            y = X['y_0'].iloc[i]\n",
    "            z = X['z_0'].iloc[i]\n",
    "            vector_coords = [x, y, z]\n",
    "            units = unit_vector(vector_coords)\n",
    "            vectors_0.append(units)         \n",
    "        \n",
    "        vectors_1 = []\n",
    "        for i in range(0, len(X)):\n",
    "            x = X['x_1'].iloc[i]\n",
    "            y = X['y_1'].iloc[i]\n",
    "            z = X['z_1'].iloc[i]\n",
    "            vector_coords = [x, y, z]\n",
    "            units = unit_vector(vector_coords)\n",
    "            vectors_1.append(units)\n",
    "        \n",
    "        angles = []\n",
    "        for i in range(0, len(vectors_0)):\n",
    "            angle = angle_btw_vectors(vectors_0[i], vectors_1[i])\n",
    "            angles.append(angle)\n",
    "            \n",
    "        return angles\n",
    "    \n",
    "    angles = calculate_angles(X)\n",
    "    X['angles'] = angles\n",
    "    \n",
    "    return X,y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X, y = preprocessing_features(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>z_0</th>\n",
       "      <th>charge_x</th>\n",
       "      <th>dist_from_refp_x</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>charge_y</th>\n",
       "      <th>dist_from_refp_y</th>\n",
       "      <th>...</th>\n",
       "      <th>subst_name_y_LEU1</th>\n",
       "      <th>subst_name_y_LIG1</th>\n",
       "      <th>subst_name_y_PRO1</th>\n",
       "      <th>subst_name_y_SER1</th>\n",
       "      <th>subst_name_y_THR1</th>\n",
       "      <th>subst_name_y_UNK0</th>\n",
       "      <th>subst_name_y_UNK1</th>\n",
       "      <th>subst_name_y_UNK2</th>\n",
       "      <th>subst_name_y_VAL1</th>\n",
       "      <th>angles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>-0.0776</td>\n",
       "      <td>1.085904</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.694086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>1.779395</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>-0.0776</td>\n",
       "      <td>1.085904</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.616520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.540815</td>\n",
       "      <td>1.447527</td>\n",
       "      <td>-0.876644</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>1.776555</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>-0.0776</td>\n",
       "      <td>1.085904</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.618726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.523814</td>\n",
       "      <td>1.437933</td>\n",
       "      <td>0.906397</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>1.778619</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>-0.0776</td>\n",
       "      <td>1.085904</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.617095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.027803</td>\n",
       "      <td>2.198949</td>\n",
       "      <td>0.014154</td>\n",
       "      <td>0.1537</td>\n",
       "      <td>2.199122</td>\n",
       "      <td>-0.013324</td>\n",
       "      <td>1.132466</td>\n",
       "      <td>0.008276</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>1.132609</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        x_0       y_0       z_0  charge_x  dist_from_refp_x       x_1  \\\n",
       "0  0.002150 -0.006031  0.001976    0.0194          0.006696 -0.012698   \n",
       "1  1.011731  1.463751  0.000277    0.0194          1.779395 -0.012698   \n",
       "2 -0.540815  1.447527 -0.876644    0.0194          1.776555 -0.012698   \n",
       "3 -0.523814  1.437933  0.906397    0.0194          1.778619 -0.012698   \n",
       "4 -0.027803  2.198949  0.014154    0.1537          2.199122 -0.013324   \n",
       "\n",
       "        y_1       z_1  charge_y  dist_from_refp_y  ...  subst_name_y_LEU1  \\\n",
       "0  1.085804  0.008001   -0.0776          1.085904  ...                  0   \n",
       "1  1.085804  0.008001   -0.0776          1.085904  ...                  0   \n",
       "2  1.085804  0.008001   -0.0776          1.085904  ...                  0   \n",
       "3  1.085804  0.008001   -0.0776          1.085904  ...                  0   \n",
       "4  1.132466  0.008276    0.0464          1.132609  ...                  0   \n",
       "\n",
       "   subst_name_y_LIG1  subst_name_y_PRO1  subst_name_y_SER1  subst_name_y_THR1  \\\n",
       "0                  1                  0                  0                  0   \n",
       "1                  1                  0                  0                  0   \n",
       "2                  1                  0                  0                  0   \n",
       "3                  1                  0                  0                  0   \n",
       "4                  1                  0                  0                  0   \n",
       "\n",
       "   subst_name_y_UNK0  subst_name_y_UNK1  subst_name_y_UNK2  subst_name_y_VAL1  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "     angles  \n",
       "0  2.694086  \n",
       "1  0.616520  \n",
       "2  0.618726  \n",
       "3  0.617095  \n",
       "4  0.001237  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "del(train)\n",
    "X.to_csv('/home/dionizije/Desktop/Code/Predicting molecular properties/Features/X_final.csv')\n",
    "np.savetxt('/home/dionizije/Desktop/Code/Predicting molecular properties/Features/y_final.csv', y, delimiter = \",\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting aside data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8)\n",
    "\n",
    "X_train.to_csv('/home/dionizije/Desktop/Code/Predicting molecular properties/Features/X_train_final.csv')\n",
    "np.savetxt('/home/dionizije/Desktop/Code/Predicting molecular properties/Features/y_train_final.csv', y_train, delimiter = \",\")\n",
    "\n",
    "X_test.to_csv('/home/dionizije/Desktop/Code/Predicting molecular properties/Features/X_test_final.csv')\n",
    "np.savetxt('/home/dionizije/Desktop/Code/Predicting molecular properties/Features/y_test_final.csv', y_test, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for cross validation of the training set and mean absolute error between the predictions and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluation(model, X_train, y_train):\n",
    "    \"\"\"Cross validation on the training set\"\"\"\n",
    "    model = KerasRegressor(build_fn = model, epochs = 50)\n",
    "    scoring = ['neg_mean_squared_error', 'neg_mean_absolute_error']\n",
    "    scores = pd.DataFrame(cross_validate(model, X_train, y_train, scoring = scoring, cv = 3))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test_evaluation(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Evaluation of the model (MAE) on the test set\"\"\"\n",
    "    model = model()\n",
    "    early_stopper = EarlyStopping(patience=15, monitor='val_loss', min_delta=0, mode='min', restore_best_weights = True)\n",
    "    history = model.fit(X_train, y_train, callbacks = [early_stopper], validation_data = (X_test, y_test), epochs = 50)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mean_absolute_error = mae(y_test, y_pred)\n",
    "    print('Mean absolute error on the test set is {}'.format(mean_absolute_error))\n",
    "    return mean_absolute_error, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with 1 hidden layer and Adam optimizer, all default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def model_1():\n",
    "    \"\"\" Baseline model + 1 hidden layer + dropout\"\"\"\n",
    "    K.backend()\n",
    "    model = Sequential()\n",
    "    \n",
    "    #input layer\n",
    "    model.add(Dense(int(X_train.shape[1]), input_dim = int(X_train.shape[1])))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    #hidden layer\n",
    "    model.add(Dense(int(X_train.shape[1]/2)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    \n",
    "    #output layer\n",
    "    model.add(Dense(1))\n",
    "    adam = optimizers.Adam()\n",
    "    model.compile(loss = 'mean_squared_error', optimizer= adam)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('/home/dionizije/Desktop/Code/Predicting molecular properties/Features/X_train_final.csv', index_col = 0)\n",
    "y_train = pd.read_csv('/home/dionizije/Desktop/Code/Predicting molecular properties/Features/y_train_final.csv', header = None)\n",
    "X_test = pd.read_csv('/home/dionizije/Desktop/Code/Predicting molecular properties/Features/X_test_final.csv', index_col = 0)\n",
    "y_test = pd.read_csv('/home/dionizije/Desktop/Code/Predicting molecular properties/Features/y_test_final.csv', header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation on the training set of the model with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_1_cross_valid_score = evaluation(model_1, X_train, y_train) #Calculates the cross validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6841.771627</td>\n",
       "      <td>36.589580</td>\n",
       "      <td>-9.189185</td>\n",
       "      <td>-1.978522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6964.458209</td>\n",
       "      <td>31.311657</td>\n",
       "      <td>-10.181463</td>\n",
       "      <td>-2.116645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7324.525281</td>\n",
       "      <td>33.686052</td>\n",
       "      <td>-10.904482</td>\n",
       "      <td>-2.126167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time  test_neg_mean_squared_error  \\\n",
       "0  6841.771627   36.589580                    -9.189185   \n",
       "1  6964.458209   31.311657                   -10.181463   \n",
       "2  7324.525281   33.686052                   -10.904482   \n",
       "\n",
       "   test_neg_mean_absolute_error  \n",
       "0                     -1.978522  \n",
       "1                     -2.116645  \n",
       "2                     -2.126167  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_cross_valid_score = pd.read_csv('/home/dionizije/Desktop/Code/Predicting molecular properties/Models_final/Model_1.csv',\n",
    "                                       index_col = [0])\n",
    "model_1_cross_valid_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the model on the test set and plotting learning history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_1_mae, history_model_1 = test_evaluation(model_1, X_train, y_train, X_test, y_test) #Returns history and MAE on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_1_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.973654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_1_mae\n",
       "0     1.973654"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_mae_score = pd.read_csv('/home/dionizije/Desktop/Code/Predicting molecular properties/Models_final/Model_1_mae.csv',\n",
    "                               index_col = [0])\n",
    "model_1_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean absolute error is basically the same as on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fee0da79250>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_1_history = pd.read_csv('/home/dionizije/Desktop/Code/Predicting molecular properties/Models_final/Model_1_history.csv', \n",
    "                             index_col = [0])\n",
    "sns.lineplot(data = model_1_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model hasn't converged after 50 epochs, and the loss on the validation set is fluctuating, which should be improved with hyper-parameter optimization and regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - default values with added batch normalization for regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def model_2():\n",
    "    K.backend()\n",
    "    model = Sequential()\n",
    "    #input layer\n",
    "    model.add(Dense(int(X_train.shape[1]), input_dim = int(X_train.shape[1])))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    #hidden layer\n",
    "    model.add(Dense(int(X_train.shape[1]/2)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    \n",
    "    #output layer\n",
    "    model.add(Dense(1))\n",
    "    adam = optimizers.Adam()\n",
    "    model.compile(loss = 'mean_squared_error', optimizer= adam)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_2_cross_valid_score = evaluation(model_2, X_train, y_train) #Cross validation on the default model with BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9037.327654</td>\n",
       "      <td>52.054146</td>\n",
       "      <td>-21.966199</td>\n",
       "      <td>-2.910550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9283.378555</td>\n",
       "      <td>45.239434</td>\n",
       "      <td>-20.786696</td>\n",
       "      <td>-2.856885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9487.053614</td>\n",
       "      <td>50.274308</td>\n",
       "      <td>-18.566012</td>\n",
       "      <td>-2.636477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time  test_neg_mean_squared_error  \\\n",
       "0  9037.327654   52.054146                   -21.966199   \n",
       "1  9283.378555   45.239434                   -20.786696   \n",
       "2  9487.053614   50.274308                   -18.566012   \n",
       "\n",
       "   test_neg_mean_absolute_error  \n",
       "0                     -2.910550  \n",
       "1                     -2.856885  \n",
       "2                     -2.636477  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_cross_valid_score = pd.read_csv('/home/dionizije/Desktop/Code/Predicting molecular properties/Models_final/Model_2.csv',\n",
    "                                        index_col = [0])\n",
    "model_2_cross_valid_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With added batch normalization : training time is increased and the scores are worse than on the default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_2_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.580056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_2_mae\n",
       "0     2.580056"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_mae_score = pd.read_csv('/home/dionizije/Desktop/Code/Predicting molecular properties/Models_final/Model_2_mae.csv',\n",
    "                               index_col = [0])\n",
    "model_2_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean absolute error on the test set is also higher with batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fee0da01110>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_2_history = pd.read_csv('/home/dionizije/Desktop/Code/Predicting molecular properties/Models_final/Model_2_history.csv', \n",
    "                             index_col = [0])\n",
    "sns.lineplot(data = model_2_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fluctuation in validation set loss has been reduced, but at the cost of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_histories = pd.DataFrame({'model_1_loss': model_1_history['loss'],\n",
    "                                'model_2_loss': model_2_history['loss'], \n",
    "                                'model_1_val_loss': model_1_history['val_loss'], \n",
    "                                'model_2_val_loss': model_2_history['val_loss']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fee0d989410>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = sns.lineplot(data = [model_histories['model_1_loss'], model_histories['model_2_loss']],\n",
    "                   palette=sns.color_palette(\"hls\", 2), dashes = False)\n",
    "labels = ['Model 1', '+ Batch norm']\n",
    "plt.legend(title = 'Training loss', labels = ['Model 1', '+Batch norm'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fee0d842810>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = sns.lineplot(data = [model_histories['model_1_val_loss'], model_histories['model_2_val_loss']],\n",
    "                     palette=sns.color_palette(\"hls\", 2), dashes = False)\n",
    "labels = ['Model 1', '+ Batch norm']\n",
    "plt.legend(title = 'Validation loss', labels = ['Model 1', '+Batch norm'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison plots of validation and training losses of models with and without batch normalization where it's clear that there are less fluctuations with batch normalization, but accuracy is lower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data subsampling for paramater tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def subsampling(data, number_of_samples):\n",
    "    \"\"\" Samples the same number of values for each type to reduce memory issues and reduce training time\"\"\"\n",
    "    \n",
    "    unique_types = list(train['type'].unique())\n",
    "    num_of_each_type = int(number_of_samples/len(unique_types))\n",
    "    subsampled_types = []\n",
    "    for types in unique_types:\n",
    "        samples = train.query(\"type ==  '{}'\".format(types)).sample(num_of_each_type)\n",
    "        subsampled_types.append(samples)\n",
    "    train_subsampled = pd.concat(subsampled_types)\n",
    "    \n",
    "    #Stats of scalar coupling constant\n",
    "    data_distribution = pd.DataFrame(train['scalar_coupling_constant'].describe())\n",
    "    data_distribution.rename(columns = {'scalar_coupling_constant': 'Train_scalar_coupling_constant'}, \n",
    "                             inplace = True)\n",
    "    \n",
    "    data_subsample_distribution = pd.DataFrame(train_subsampled['scalar_coupling_constant'].describe())\n",
    "    data_subsample_distribution.rename(columns = {'scalar_coupling_constant': 'Train_subsample_scalar_coupling_constant'},\n",
    "                                       inplace = True)\n",
    "    \n",
    "    #Distribution plot\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.distplot(train['scalar_coupling_constant'], ax = ax, label = 'Train')\n",
    "    sns.distplot(train_subsampled['scalar_coupling_constant'], ax = ax, label = 'Train_subsampled')\n",
    "    ax.legend()\n",
    "    plt.title('Distribution of whole train dataset vs subsampled')\n",
    "    plt.show()\n",
    "    \n",
    "    print(data_distribution)\n",
    "    print(data_subsample_distribution)\n",
    "    return train_subsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dionizije/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/home/dionizije/Desktop/Code/Predicting molecular properties/Features/train_final.csv', \n",
    "                   index_col = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEXCAYAAACjyo8UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOzdd3gc1bn48e+7Xc2SG8aWK4YAxmBjTDEYErohBZLApYRACAmBhJsbkvyAXBICpAG593K5F1IgtFANCRCTcEMooSRgbAO2ccHYuMpVlqy+fd/fHzMrr+SVtZJWXnn9fp5nH83OnJk5s7N65+yZM+eIqmKMMaZ4eQqdAWOMMf3LAr0xxhQ5C/TGGFPkLNAbY0yRs0BvjDFFzgK9McYUuX060IvIb0TkR3na1lgRaRERr/v+NRH5Wj627W7v/0Tksnxtrwf7/amIbBeRLX3YxldE5B+9XPdmEXm0t/vuqzx/Rwp6LHsjEXlIRH5a6HzsTl/+1/MdJ7ri6+8dFIqIrAVGAAkgCSwDfg/cq6opAFW9qgfb+pqqvtxVGlVdD5T3Ldft+7sZOFBVL8nY/ln52HYP8zEG+B4wTlW37en991Uu5607uX5H8k1EHgJqVPWHxbAfU1jFXqL/rKpWAOOA24DrgfvzvRMRKdYL5jigbm8M8rko4vNmTAfFHugBUNVGVZ0DXABcJiKToePPQhEZJiJ/FpEGEakXkTdFxCMijwBjgefdqpnrRGS8iKiIXCEi64FXM+ZlBo+JIjJPRBpF5E8iMsTd16dEpCYzjyKyVkROE5FZwL8DF7j7W+Qub/+J5+brhyKyTkS2icjvRaTSXZbOx2Uist6tdrmxq89GRCrd9Wvd7f3Q3f5pwEvAKDcfD2VZ93UR+aI7PdPd79nu+9NEZGGn9P8hIjtEZI2InJUxf5SIzHE/91Ui8vXd5Pc4EXnLPU+LRORTXaTL6by5aZ8WkS3ueXpDRA7L2E7md+RTIlIjIt9zP/fNInL5bvI6wf2MmkXkJWBYp+VZ9ysiVwJfAq5z8/68O/8GEfnY3d4yEfl8xrYOdPfV6J7z2RnLDhGRl9zPd4WI/Mvu9tMpj78Rkf/oNO9PIvJdd/p6Edno5mmFiJzaxWdxtpvnZjf99935u1TruefowIxZw9z8N7vHOM5NJyJyp3suGkVksez83/60iLwvIk0iskGcX8np7ae/B5e7y3aIyFUicrS7jQYRuTsj/VdE5J8i8r/ufj7s6jjd9F8VkeXudl9M59dddrq7fqO7D+lqO3mlqkX5AtYCp2WZvx642p1+CPipO/0L4DeA332dCEi2bQHjAcWpCioDSjLm+dw0rwEbgclumj8Cj7rLPoXzczlrfoGb02kzlr+GUw0B8FVgFXAATnXRM8AjnfJ2n5uvKUAUOLSLz+n3wJ+ACnfdj4Aruspnp3VvBf7Xnf534GPg9oxld7nTXwHiwNcBL3A1sCnj830d+BUQAqYCtcCpnT8LoBqoA87GKaSc7r4fnst3INt5y/g8K4Ag8N/Awox1HmLnd+RTOFWBt+J8R84G2oDBXez/beC/3O2eBDRnntdc95sx73xglHvsFwCtwEh32RPAje6yEDDTnV8GbAAux6mqnQZsBw7raj+d9nmSu376XA0Gwm4+DnaXjcr4fCd2sZ3NwIkZ25iW8d34R6e0ilN1mc5fs5uPIHBXOj1wJvAuUIUTMA/N+Dw+BRzufh5HAFuBczt9D37jflZnABHgOWA/nO/ZNuCTGXlMANe65/0CoBEYkuV/81yc/81D3c/7h8Bb7rJhQBNwnruda93tfq2/4+E+UaLvZBMwJMv8ODASpz46rqpvqnt2duNmVW1V1XAXyx9R1SWq2gr8CPgXcW/W9tGXgP9S1dWq2gL8ALhQOv6auEVVw6q6CFiEE/A7cPNyAfADVW1W1bXAfwJfzjEfrwOfdKdPwrlYpt9/0l2etk5V71PVJPAwzmc9Qpz7ADOB61U1oqoLgd91kYdLgBdU9QVVTanqS8ACnIDbEx3Om6o+4B5/FOfCMkXcX0hZxIFb3e/IC0ALTsDrQETGAkcDP1LVqKq+AXQoMfdwv6jq06q6yT322cBK4JiMfI3DCboRVU2Xkj8DrFXVB1U1oarv4RQ6zuvuQ3K9iRMUT3Tfnwe8raqbcO59BYFJIuJX1bWq+nEX24m76Qap6g43H7n6i6q+4X5ONwIz3O9NHOdCeQjOhWi5qm4GUNXXVPUD97NajHMh/GSn7f7E/az+hnPRfEJVt6nqRve4j8xIuw34b/e8zwZWAJ/OktdvAL9w85IAfg5MdUv1ZwPLVPUPqhrHubj3upFDT+yLgb4aqM8y/5c4V+K/ichqEbkhh21t6MHydThX8WFdpO2JUe72Mrftw7n5nJb5BWoj+43iYUAgy7aqc8zH28AnRGQETkn898AYERmGE4DeyJYfVW1zJ8vdY6lX1eYc8jAOON/9ad0gIg04F4mROeY3rf28iIhXRG5zq0SacH4FQNfnqc79B07r6rMdBexwL/Jp7Z9zL/aLiFwqIgszjn1yRvrrcEq180RkqYh81Z0/Dji202f2JWD/rvaTyS3sPAlc5M66GHjMXbYK+A7ORWqbiDwpIqO62NQXcQLdOrf6ZUYu+3e1ny+3YFOPc0F7FbgbuAfYKiL3isggABE5VkT+Lk6VZCNwFbt+tlszpsNZ3mee142dCn7rcM5xZ+OAuzI+63qc81Ltps88FqX7GJIX+1SgF5GjcT7wXZr6uSWr76nqAcBnge9m1MN1VbLvrsQ/JmN6LE4JZDtO6aE0I19eYHgPtrsJ5wuVue0EHb+oudjOzpJg5rY25rKyG7DfBf4NWKKqMeAt4LvAx6q6PYfNbAKGiEhFDnnYgPMrqSrjVaaqt3WVxRzmXwycA5wGVOL8rIe+151uBgaLSFnGvLE92G+HvLslwvuAa4ChqloFLEmnV9Utqvp1VR2FU6r8lVvPvQF4vdNnVq6qV2fbTxeeAM5z83Aszi8C3P0+rqozcb5DCtyebQOqOl9Vz8GpGnkOeMpd1Pl/IdsFaEzG8nKcX+Sb3O3+j6oeBRwGfAL4f27Sx4E5wBhVrcSppunLOa0Wkcz1x6bz0MkG4BudPu8SVX0L5zuReSxCxxjRb/aJQC8ig0TkMzglk0dV9YMsaT4jzg0twalHS7ovcALoAb3Y9SUiMklESnHqdf/gVl18BITcG0Z+nHq8YMZ6W4HxItLV+XkCuFacm33lOD8PZ3cqaXbLzctTwM9EpML9R/4u0JO23q/jBJ90Nc1rnd53l4cNOBeHX4hISESOAK7ALTV28ijwWRE50y0Rh8S5QTq6i83nct4qcO5h1OEEnJ/nku/uqOo6nGqlW0QkICIzcQoQue63c97LcAJpLYA4N4EnpxeKyPkZn8MON20S+DPOr64vi4jffR0tIod2sZ9sx/K+u9/fAS+qaoO7z4NF5BQRCeLUcYfZ+T/Tzj3+L4lIpVtl0ZSRbhFwmIhMFZEQzq+Dzs4W52Z/APgJ8I6qbnCP41j3f6jVzUN6uxU4vxQjInIMzoW1L/YDvu1+fufj1MG/kCXdb4AfyM4b65VueoC/uMf6Bbea9dvk+Muqr4o90D8vIs04V9kbcW6MddVK4iDgZZw617eBX6nqa+6yXwA/dH+Ofb8H+38E52bSFpybPt8GpxUQ8E2cf5yNOF/SzFY4T7t/60QkW13mA+623wDW4HzB/7UH+cr0r+7+V+P80nnc3X6uXsf5p3qji/e5uAinRLsJeBb4sVv/3oF7UTgH58ZvLc55/X90/T3O5bz9Hudn+EacZy3m9iDf3bkYpwRcD/zY3Veu+70fp067QUSeU9VlOPdP3sYJzocD/8xIfzTwjoi04JRk/01V17hVYmcAF+J8vltwSt3BbPvZzbE8gfPr4/GMeUGcZsvb3e3uh3NusvkysNatproK534LqvoRTiHoZZx7DtkerHsc5/OrB47CqXoCGITzK2cHzmdZB6RbCH0TuNX9/7+Jnb8geusdnBixHfgZcJ6q1nVOpKrP4ny+T7rHugQ4y122HeeG+m1uXg+i4znsN+k76cYYY7IQka/gtIyZWei89Faxl+iNMWafZ4HeGGOKnFXdGGNMkbMSvTHGFLkB16nTsGHDdPz48YXOhjHG7FXefffd7ao6PNuyARfox48fz4IFCwqdDWOM2auIyLqullnVjTHGFDkL9MYYU+Qs0BtjTJEbcHX0xpjcxONxampqiEQihc6K2YNCoRCjR4/G7/fnvI4FemP2UjU1NVRUVDB+/Hg6dqxoipWqUldXR01NDRMmTMh5Pau6MWYvFYlEGDp0qAX5fYiIMHTo0B7/irNAb8xezIL8vqc35zynQC8is8QZ+HeVZBl5SUROEpH3RCQhIud1WnaZiKx0X5f1OIfGGGP6pNs6enf0o3twBmKuAeaLyBy3f+y09TgD6H6/07pDcPqRno4zEMK77ro78pP94vG7N1ezZnsrP/v84YXOitlLPf7O+rxu7+Jjx+52eV1dHaee6gzCtmXLFrxeL8OHOw9mzps3j0Ag0O0+Lr/8cm644QYOPniXYXdNHuVyM/YYYJWqrgYQkSdxBn9oD/TqDCqNiKQ6rXsm8JKq1rvLXwJm4QxiYDLMXV3HR1tbCp0NY3I2dOhQFi5cCMDNN99MeXk53/9+x/FdVBVVxePJXnnw4IMP9ns+TW5VN9V0HMC2htwHj85pXRG5UkQWiMiC2traHDddXNpiSSLxXUZhM2avs2rVKiZPnsxVV13FtGnT2Lx5M1deeSXTp0/nsMMO49Zbb21PO3PmTBYuXEgikaCqqoobbriBKVOmMGPGDLZt21bAoyguuQT6bDX/ufZtnNO6qnqvqk5X1enpn377mrZYkrAFelMkli1bxhVXXMH7779PdXU1t912GwsWLGDRokW89NJLLFu2bJd1Ghsb+eQnP8miRYuYMWMGDzzQkxEtze7kEuhr6DhS+Wiyj36e73X3KWEr0ZsiMnHiRI4++uj290888QTTpk1j2rRpLF++PGugLykp4ayzzgLgqKOOYu3atXsqu0Uvl0A/HzhIRCa4o7BfiDP4cC5eBM4QkcEiMhhnkOIXe5fV4tYWTxBPKolk59scxux9ysrK2qdXrlzJXXfdxauvvsrixYuZNWtW1nbgmTdvvV4viURij+R1X9BtoFfVBHANToBeDjylqktF5FYR+RyAiBwtIjU4I5z/VkSWuuvWAz/BuVjMB25N35g1HYVjTmk+krBAb4pLU1MTFRUVDBo0iM2bN/Pii1bW29Ny6gJBVV8AXug076aM6fk41TLZ1n0AsMq2brS5gT4cS1IetJ4pTM911xyyUKZNm8akSZOYPHkyBxxwACeccEKhs7TPGXBjxk6fPl33tYFHVJUD/v0FVOHN605mzJDSQmfJ7AWWL1/OoYceWuhsmALIdu5F5F1VnZ4tvXWBMABEEynS11u7IWuMyTcL9ANAutoGsCaWxpi8s0A/ALTFdrYuiMTtZqwxJr8s0A8AYSvRG2P6kQX6AaBD1U3MAr0xJr8s0A8AmYE+mrBAb4zJL2uwPQCE4zvr6K1Eb3ptQZ57gpx+eX63ZwrGSvQDgLW6MXujuro6pk6dytSpU9l///2prq5ufx+LxXLaxuWXX86KFSv6NZ/pnjEL7Xe/+x3f+c53erTO6NGjaWho6PO+rUQ/AGQGemt1Y/YW1h/93sNK9AOAtboxxWRP9Ef/5JNPMnnyZKZMmcLJJ58M7FpinjVrFv/4xz/a31977bVMmzaN008/nbq6OgDuvPNOJk2axJQpU7jkkksAmDt3LjNmzODII4/khBNOYOXKle3b/8IXvsBnPvMZJkyYwK9//Wt++ctfcuSRR3L88ce3l7xnzpzJd77zHWbMmMHhhx9Otif9t27dyhe+8AWmT5/OMcccw9y5cwGora3l9NNPZ9q0aVx99dXkq+cCC/QDQLpEL2JPxpri0N/90d9yyy288sorLFq0iGeffbbb/DQ2NnLcccfx3nvvMWPGDH7yk58AcMcdd7Bw4UIWLVrE3XffDcChhx7KP/7xD95//31+9KMf8cMf/rB9O0uXLmX27NnMnTuX66+/nsGDB/P+++9z1FFH8eijj7ani0ajvP3229x111187Wtf2yU/3/72t7nuuutYsGABTz31VHuaH//4x5x88sm89957zJo1i02b8tOru1XdDABh94GpyhK/BXpTFLL1R3///feTSCTYtGkTy5YtY9KkSR3W6dwf/Ztvvtnl9k844QQuvfRSzj//fL7whS90mx+fz8f5558PwCWXXMLFF18MwGGHHcYll1zCOeecw7nnngtAQ0MDl156KR9//PEu2znllFMoKyujrKyM8vJyPvvZzwJw+OGH89FHH7Wnu+iii9rTb9u2jZaWjsOEvvzyyx3uTezYsYNwOMwbb7zBCy84/Ueec845VFRUdHtsubAS/QDQFktS4vdS6vdaqxtTFPq7P/r77ruPW265hbVr1zJlyhR27NiBz+cjldp5jytzHyIdB7tLv3/xxRe56qqrmDdvHtOnTyeZTHLjjTdy5plnsmTJEp577rkO2wkGg+3THo+n/b3H4+mQ3672l6aqzJs3j4ULF7Jw4UI2btxISUlJ1rT5YCX6AaAtnqQ04CUU8Fodvem9AdocMlt/9LNmzerTNlevXs1xxx3Hsccey5w5c9i4cSPjx4/n/vvvR1VZt24d7777bnv6eDzOM888w3nnncfjjz/OzJkzSSaT1NTUcMoppzBz5kwee+wx2traaGxspLraGdr6oYce6lX+Zs+ezYknnshrr73GiBEjOlz4AE477TTuuecerr32WgAWLlzI1KlTOemkk3jssce44YYbeP7552lubu7dB9SJBfoBIBxLUhLwEvJ5rdWNKTr90R/9tddey5o1a1BVzjjjDCZPnoyqUl1dzeGHH87kyZOZOnVqe/rKykree+89fv7znzNkyBBmz55NIpHg4osvprm5mVQqxfXXX09FRQXXX389X/3qV7njjjvab/T21KBBgzj++ONpbm7O2rLonnvu4eqrr+bBBx8kkUhw8sknc88993DLLbdw0UUX8dRTT3HyySe3X3D6yvqjHwC+8cgC1mxvpSLkp8Tv5dGvHVvoLJm9gPVHPzDNnDmTu+++u8OFJt+sP/q9UFssSUnAR8jvsaobY0zeWdXNABCOJSn1eynxe2loixc6O8YMGLfeeivPPPNMh3kXXnghN9xwQ4Fy1L3MtvsDhQX6ASAcT1JZ4ifkt5uxpmdUtV9aaQwUN910EzfddFP3Cfchvalut6qbAaD9ZqzfS8SaV5ochUIh6urq8vb0pBn4VJW6ujpCoVCP1rMS/QDQFnOaVwZ9XiIJa3VjcjN69Ghqamqora0tdFbMHhQKhRg9enSP1rFAPwC0xRKUBnwEfB57YMrkzO/3M2HChEJnw+wFLNAPAOG4U3Xj9wjheLLo612NMXuW1dEXWDyZIp5USv3Ok7EAUau+McbkkQX6Akv3XFkScJpXgvVgaYzJLwv0BZauky8N+Ai5gd6aWBpj8snq6Ausze2iuNSttgEbZcoYk18W6AssXXWTLs2DDRBujMkvC/QFlq6mKQ14SbkPvljVjTEmnyzQF1hbbGegT6acQB+1QG+MySML9AWWHkawJOAlkbQSvTEm/3JqdSMis0RkhYisEpFduo0TkaCIzHaXvyMi4935fhF5WEQ+EJHlIvKD/GZ/79eW0eqmJGCtbowx+ddtoBcRL3APcBYwCbhIRCZ1SnYFsENVDwTuBG53558PBFX1cOAo4Bvpi4BxZFbd7GxHb61ujDH5k0uJ/hhglaquVtUY8CRwTqc05wAPu9N/AE4V5xl+BcpExAeUADGgKS85LxLhjAemgn7ndFiJ3hiTT7kE+mpgQ8b7Gnde1jSqmgAagaE4Qb8V2AysB/5DVes770BErhSRBSKyYF/ria+9RO/PKNFb80pjTB7lEuiz9a7VuQPsrtIcAySBUcAE4HsicsAuCVXvVdXpqjp9+PDhOWSpeLTFEwS8HnxeT3tbeusCwRiTT7kE+hpgTMb70cCmrtK41TSVQD1wMfBXVY2r6jbgn0DWwWv3VelBRwD8Xg8+twdLY4zJl1wC/XzgIBGZICIB4EJgTqc0c4DL3OnzgFfVGfZmPXCKOMqA44AP85P14hB2Bx1JK7HhBI0xedZtoHfr3K8BXgSWA0+p6lIRuVVEPucmux8YKiKrgO8C6SaY9wDlwBKcC8aDqro4z8ewV2uL7yzRA4QCXmt1Y4zJq5wemFLVF4AXOs27KWM6gtOUsvN6LdnmG8fj76xn1dYWIvEkj7+zHoBEMmV19MaYvLJuigsslkwR8O48DX6vDSdojMkvC/QFFk+mCPh2noaAz0MkYYHeGJM/FugLLJZI4c8o0fs8VqI3xuSXBfoC61x1E/CJ1dEbY/LKAn2BxRIdq258Ho+1ujHG5JUF+gKL71Ki91g7emNMXlmgL6CUKvGk4vdltrqxJ2ONMfllgb6A0gONdLgZ6/VYHb0xJq8s0BdQeuhAn2dnn3ABC/TGmDyzQF9AiZRz09WbEej9XiGeVBJJuyFrjMkPC/QF1LlEv1/dPIIeJ8BHEhbojTH5YYG+gNKB3usRBjcu47R5V3Bk+B0Ae2jKGJM3FugLKJER6Ic2LgGgKtUA2OAjxpj8sUBfQJlVN0OalgFQrs2ABXpjTP5YoC+gzKqbIY1OoC/TFmDnWLLGGNNXFugLKF114ydJZfNKAEpTrYCV6I0x+WOBvoDSJfqR0dV4NQFAWcqpummzQG+MyRML9AWUDvSjwh8BEA4MpSTp1tFb1Y0xJk8s0BdQe4m+bQUxXzk7Kg8llLQ6emNMflmgL6CkOoF+ROuH7Bh0CFF/JaGEU6K3js2MMfligb6AEskUPhIMb11J/aBJxPyDCCWaAHtgyhiTPxboCyiZUg6UTfg0xo5BhxLzDcKfaEFIWYneGJM3FugLKKnKZM8aAOorJxH3V+AhRZU3aoHeGJM3FugLKJlSJshmUuKjuWwcMf8gAEb4w1Z1Y4zJGwv0BZRMKaVEiXtDqHiJ+ZxAP8wXsUBvjMkbC/QFlEgpQWIkvSUA7SX64b6wPTBljMkbC/QFlEwpJRIj6Q0BOwP9EK9V3Rhj8scCfQElU0qpxEi0B/oKAIZ42wjHE4XMmjGmiFigL6BkSikhRtLjBnq3jr5K2qxEb4zJGwv0BZRIKaUSba+6SfjKSOGhSlqtCwRjTN5YoC+gZCpFiHh71Q0ixP0VVNBq3RQbY/LGAn0BOTdjd5bowbkhW6FWojfG5E9OgV5EZonIChFZJSI3ZFkeFJHZ7vJ3RGR8xrIjRORtEVkqIh+ISKjz+vuqREoJESPhNq8EJ9CXa4s9GWuMyZtuA72IeIF7gLOAScBFIjKpU7IrgB2qeiBwJ3C7u64PeBS4SlUPAz4FxPOW+71cMqWEiJL0hJi4/mkmrn8aX6KN0ug2wtE4LHiw0Fk0xhSBXEr0xwCrVHW1qsaAJ4FzOqU5B3jYnf4DcKqICHAGsFhVFwGoap2qWlHV1R7ovcH2eQlvCSWpVhIqxFMFzJwxpmjkEuirgQ0Z72vceVnTqGoCaASGAp8AVEReFJH3ROS6bDsQkStFZIGILKitre3pMey1ksmUW3WzszYr4Q0RSrUB0JaQQmXNGFNEcgn02aKN5pjGB8wEvuT+/byInLpLQtV7VXW6qk4fPnx4DlkqEqk4XlId6uiTnhBBN9BHkhbojTF9l0ugrwHGZLwfDWzqKo1bL18J1LvzX1fV7araBrwATOtrpouFPxUBaH9gCpwSvVcTBIlZid4Ykxe5BPr5wEEiMkFEAsCFwJxOaeYAl7nT5wGvqqoCLwJHiEipewH4JLAsP1nf+/lTUYAOVTfpDs4qaSVsJXpjTB74ukugqgkRuQYnaHuBB1R1qYjcCixQ1TnA/cAjIrIKpyR/obvuDhH5L5yLhQIvqOpf+ulY9jrtJXpvCG/SmU4H/UHSSjhRWrC8GWOKR7eBHkBVX8Cpdsmcd1PGdAQ4v4t1H8VpYmk68WUJ9OmHp5wSfVnB8maMKR72ZGwBZau6SU9XSittVnVjjMkDC/QFFNAsN2Pd6UG0EbabscaYPLBAX0CB9hJ9RvPK9M1YabXmlcaYvLBAX0ABdQJ9MlvVDa3WvNIYkxcW6AsoXXWTWUePeFBv0Gl1YyV6Y0weWKAvoIDGgI4legD8JU6rGyvRG2PywAJ9gaQ7NIOdN2DTxF/KEI+V6I0x+WGBvkDiyRQlpEv0wY4L/SEqpc2aVxpj8sICfYHEkilKJEoCH+rxd1zoK6FC2ogkCpM3Y0xxsUBfILGEU6KPeYK7LvSHqCBsJXpjTF5YoC+QeDJFiCgJyRLofSWU2wNTxpg8sUBfIPGEEpI4MU+WIXT9IcpoI2xVN8aYPLBAXyCxZIoSosSzBXpfCC8pUkkbXtcY03cW6Ask3eomkbWO3ukGwZMI7+FcGWOKkQX6Aokl3FY3nR+WAvA5gd6XtEBvjOk7C/QFEncHBs9adeN35vncPuqNMaYvLNAXSMwN9Lt0fwDtJfpAykr0xpi+y2mEKZN/8aRSQpSmLCX6xVujHAGEUm08OncdHnGaWV587Ng9nEtjTDGwEn2BxBMpSiSWtY4+XcqvkDYSSd3TWTPGFBkL9AWys+qmZJdl6U7OKmgjlkzt6awZY4qMBfoCiSeSlBAl6du1RJ/y+EnhoULCxBMW6I0xfWN19IWw4EHiq334JEVF63omrn+643IRYhKkgjZ2WIneGNNHVqIvEE0/9erJfq2NeUJUSBtxC/TGmD6yQF8g6UCv3uyBPu4JMYiw1dEbY/rMAn2BpBLOoCN07ovelfA448ZaHb0xpq8s0BeIJp1AL11U3SS9Tp/0MWteaYzpIwv0BSLJdIm+q0Dv3Iy1Er0xpq8s0BdK0ulsXr3Zq25S3iAVYu3ojTF9Z4G+QCTllOhTkj3Q4w1STph4IrkHc2WMKUYW6AskXXWT6uJmLN4gPkkhibY9mCtjTDGyQF8gknKaV3YV6JNeZ0ASf6xpj+XJGFOcLNAXiKebqpt0xyLiTlQAACAASURBVGb+RPMey5MxpjjlFOhFZJaIrBCRVSJyQ5blQRGZ7S5/R0TGd1o+VkRaROT7+cn23s+b2n3VTTI9xGDEAr0xpm+6DfQi4gXuAc4CJgEXicikTsmuAHao6oHAncDtnZbfCfxf37NbPNpL9LtpRw9AtHFPZckYU6RyKdEfA6xS1dWqGgOeBM7plOYc4GF3+g/AqSLOaBkici6wGlianywXB28qTgIvKt6syxNuHb3ErERvjOmbXAJ9NbAh432NOy9rGlVNAI3AUBEpA64Hbul7VouLLxUjSqDL5Um3T3p/vIVEytrSG2N6L5dAL1nmdX4uv6s0twB3qmrLbncgcqWILBCRBbW1tTlkae/n024CvVuiH0QrTeHEnsqWMaYI5dIffQ0wJuP9aGBTF2lqRMQHVAL1wLHAeSJyB1AFpEQkoqp3Z66sqvcC9wJMnz59n+jcxZ+K7jbQpyQ9+EgbDeE4Q8q6TmuMMbuTS6CfDxwkIhOAjcCFwMWd0swBLgPeBs4DXlVVBU5MJxCRm4GWzkF+X+XTOLGunooFECHhCVJBmLVtMaBsj+XNGFNcug30qpoQkWuAFwEv8ICqLhWRW4EFqjoHuB94RERW4ZTkL+zPTBcDPzFiuynRg9uDpbTRGI7voVwZY4pRTkMJquoLwAud5t2UMR0Bzu9mGzf3In9FK6Ax4rsr0eN0bFblCdNggd4Y0wf2ZGyBBDSHEr0nSJUnQmObBXpjTO9ZoC+QIFHisvtAn/CGqLSqG2NMH1mgL5CAxkjI7mvOkp6g2+omtodyZYwpRhboC6SUCDEJ7TZN0huiTFuJxFNE49YvvTGmdyzQF0g5YWLpjsu6kPQECaXaEFJ2Q9YY02sW6AshmSAgiW5L9AlvCR6UCqye3hjTexboCyCViAAQk92X6OM+5yGpYdJkLW+MMb1mgb4A4jEn0Me7qbqJ+0oBGEaT3ZA1xvSaBfoCSMacoJ3oNtCXAzAm2GJVN8aYXrNAXwCJuFOi7y7QJ7xO1U21v4UGq7oxxvSSBfoCSMajzt8cqm4UYaSv2VrdGGN6zQJ9ASRzLNEjHqL+KvbzNNMUjuN0CGqMMT1jgb4ANF2i93YT6IFIcChDaCSRUpqjNgCJMabnLNAXgLrNK9XT/WAikcAQqrQBgO3N0X7NlzGmOFmgLwBNREmpoJ7dd1MMTol+UNIN9C3WxNIY03MW6AshEaGVEF5PtqF2O4oGhlCeqAdge4uV6I0xPWeBvgAkEaGFEnye7m+uRgJDCCZbCRKzQG+M6RUL9AUgiQgtWoJPcgj0waGA83SsVd0YY3rDAn0BeJJRWgnhzyXQB4YAUB1osRK9MaZXLNAXgCcZobmHJfrqQIu1ujHG9IoF+gLwJntWRw8w0tdsJXpjTK9YoC8AbzJCKzmW6N1Av5+n2erojTG9YoG+APw9qLpJ+kqJe0vYT5qosxK9MaYXLNDvaar4Uk7VTS43YwEigaEMlUZaY0nCMRs71hjTMxbo97R4GA8p2jREuS+3oB0NZnSDYKV6Y0wPWaDf06LNAKg/SA4PxgIQDgylMtkIQK0FemNMD1mg39NiLQB4/bsfGDxTNDiE8uQOAOrshqwxpocs0O9p0SYAAoHuuyhOiwSGUBpvQEhZ1Y0xpscs0O9pbtVNqEeBfigeklRhD00ZY3rOAv0elow4gb4k1INA7z4dOy7UaiV6Y0yPWaDfw1qbnLr2ipLuBx1JiwScQH9AqM0emjLG9JgF+j2sxQ30laU9q6MHGBu0Er0xpudyCvQiMktEVojIKhG5IcvyoIjMdpe/IyLj3fmni8i7IvKB+/eU/GZ/7xNucdrDV5V2P7pUWltoBADjfPUW6I0xPdZtoBcRL3APcBYwCbhIRCZ1SnYFsENVDwTuBG53528HPquqhwOXAY/kK+N7q2hLIwn1MLzUm/M6CX854cBQxugmq7oxxvRYLiX6Y4BVqrpaVWPAk8A5ndKcAzzsTv8BOFVERFXfV9VN7vylQEhEcq+z2EtsbgzztYcX0BSJd5s2EW6khRKGl+TW/UFac9k49k9sojEcJ5ZI9Tarxph9UC6BvhrYkPG+xp2XNY2qJoBGYGinNF8E3lfVoqt7WLB2By8v38qiDQ3dpk1GmmmlhFDuBXoAmkvHMiTqnIb6VivVG2Nyl0ugz/agfufi6G7TiMhhONU538i6A5ErRWSBiCyora3NIUsDS0s0AUDNjnD3iaPNxCT3p2Inrn+aieufxh9vojRaSxlhts97urdZNcbsg3w5pKkBxmS8Hw1s6iJNjYj4gEqgHkBERgPPApeq6sfZdqCq9wL3AkyfPr1ndRoDQPPKt4AKNi6bC55Xdi6Yfvkuab3xFmKe3AN9Wrot/XjZSm2kqrdZNcbsg3Ip0c8HDhKRCSISAC4E5nRKMwfnZivAecCrqqoiUgX8BfiBqv4zX5keaFoSzse4sa37+hhfopWktxeB3m1iOV62sCVsrWKNMbnrNmK4de7XAC8Cy4GnVHWpiNwqIp9zk90PDBWRVcB3gXQTzGuAA4EfichC97Vf3o+iwJriwhRZxbjGebtNp6oEk63g63mgj7qB/kDPJta29LCC3xizT8ul6gZVfQF4odO8mzKmI8D5Wdb7KfDTPuZxwGuJC//qe5YTo0sg8VPwZW9Y1BxNUEaYuL/nDY9SHj+Eqjgsupk/WqA3xvSA1QHkQXNc+ITUECROovajLtNta4pSRgRfoOclegDKhjPRs4V1rTldn40xBrBAnxfxeIyxHqe1UGTT0i7TbWtqo0LCBAO593PTQdlwRupW1rZ4SaX2unvWxpgCsaJhHlTFNgOwQ8sp274UNAWy6zV0xw6nn5ue9FyZaV20jHGpFoLJVn77xmoqS5xuFC4+dmwvc26M2RdYiT4PRsSd1qYPJ88gEG+Ghg1Z0zU21ANQ2stAHwk6N2QnyBbqrM8bY0yOLNDnwahkDXF8/D5xBik8sC179U2z23NlSbCXgT6Qbku/xYYUNMbkzAJ9HozTjdT5R+IPlbHGfyBsWZI1XbjJKdFLL5pXAkT9g1GEiZ7N1LVaid4YkxsL9H0UT6aYKBtpCI6iujTF254joXkThHfsktbftM6ZKB3Sq32px0vUX8UhPuvF0hiTOwv0fdTSWE+11NESGkV1WZK/xyc7C3as2yVtVetqknigbFiv9xcODWeSrLWOzYwxObNA30fRTcsAiJSOpLo0ydzwGFQ80LSxQzpVZb/oOnYER4On942dmkvHUq1boXUrKbUmlsaY7lmg76PkNifQJ8v3Z3RpklYNkCgdAU0d+31rDMcZr5toGTSxT/trKnWaUk7T5TRHEn3aljFm32CBvo88tctp0yC+0sFUlzoDgjSVjN6lRL+xvonxsoXkkAP7tL+2kpHEJcAxng+tiaUxJif2wFQfBeo/YqVWUxEQSnxJALb4RjM0Mh/a6qF0CI+/s57aNR9wmCRZHh/F9jX1vd6fipeG0BiOTS5nUUuMA4bn60iMMcXKSvR9VNqwkpU6mnK/Ul3qBPqPPe6Tqlt3tqcva3K64o8O7luJHiBcPpZDPRuINO19g7QYY/Y8C/R90VZPSbSWFanRVPhTfLChnkpfgpcbRgLw7rw3efyd9QAMal0DQDwPgb6lzLmQjGxc2OdtmdzUt8a48dkP+Ghrc6GzYkyPWaDvi9oPAVipo6nwOy1gxpVEWRzej5ivjKqmFe1Jh0fWspUhpPzlfd5tS0k1MfyMbVmIWsubfrehvo3zfv0Wj72znv99dVWhs2NMj1mg7wu3xc1qrSbofpLjSyNsiARpDY5gcPPOQD8yvp4NnjHZttJj6vGxvvQwjtRlbGu2G7L9aXVtC1/49Vtsb4ly/MSh/G3pFpoj8UJny5gesUDfF9s+JOIppdk/BHGHR59QGiGpwhbfKCpbPkZSCVBlTKqGLcFxedt1/bDpTJY1bNqyJW/bNLu6468riMST/OHq4/neGQcTTaR4cenWQmfLmB6xQN8XtR+yOTCeCv/OWeNLIwCs0rF4UzEGta4lFNlCGRHqQvkL9A0jZ+IVZcjWoh2Kt+BW17bw4rItXDZjPJ8YUcG0sVWMHVLKs+/XFDprxvSIBfq+2LaMDb5xlPtT7bP2D8YJeZK8lxgPQFXzCvz1Tr1uU/kBedt1XdUUmqWCSU3/tEFI+sl9b67B7/Vw2fHjARARzj2ymrc+rmNLY6SwmTOmB6wdfW+11EJbHWsqxlDh2xloPeLckH0nMpak+Dli5a/Y7tsfgHBl356KzaQeHx8NmsGJDW/x4aYGJo0enLdtG9jWHOGP79Vw3lGjGV4e4M3nfocvGcZXeSaqcMvzSznxoOE26IvZK1iJvrdqlwOwQse0t7hJm1Aa4eNIOe8cdhORwBDGNc1nq1bhq9g/r1moG3UyQ6SFj9//e163a+Chf64lnkxx1VGD4LcnceLC7zHjgx/ypcWXMaW0jnc/Wk80kSx0No3JiQX63trmBPqliVG7BPrxpVGiKQ/zq87ipRmPcP2EP/LZ6M+oLO3lWLFZTFz/NEN0Bwn14lvyNCx4MG/b3tc9Nncdj8xdx9H7wbDHTiW1dSnrR5zK+hGnMaRpOY94bkZiLTy/aHOhs2pMTizQ99a25RCqZF20okMdPTgleoBNjWEANsbKaPANJeTP78ed9IZY6ZvIgZHFJK2aPm+2NEVojiT4V+8fCUXrWDb+K2wedgKbhx3PsvGXUZZs4omy/2Lx+lrmLNrU/QaNKTAL9L1V+yG63ySao8kOdfQAo0NRvKJsbnACfUNbnKoSP5Jug5lHW0oP4SCpYfXWhrxve1+1cmsLE2UjJ9Q/x8djzqO1tLp9WUvZWFZXf5YDkqv5RflT3PjMB6yubSlgbo3pnt2M7Q1V2LaM5KGfJ/mRUt6p6sbngTGhKA1b1jFx0D+INI5jpC/JxPVP5z0ricEHQDO01GQfpzZv5j8Adauc7pfD9TD8YNhvEky/vP/2Gd4ByYQzUEs/XCS78tHWZm4NzSbhLWHxQd9k9NZXOyyvr5zM5raNnF//Z5Z6xnLFw0Geufp4Bpflr2rOmHyyQN8bzVsg0ki46iCAXerowam+eXtHBevagtTF/Ewo7Z8nWMvLB7FcxzGsbkG/bL/d+rnwwWxnWjyw5g044oL+C/SLZsOfvgWpOHj8MPwTMPXLMOPq/tmfqzWaoLp+HjMDC3h/4rVEg0Ozptuw/2kgHn5c92uua4RvPBrkkSuOIejz9mv+jOkNq7rphZb1TmdiTYPSgT61S5rP7V9PqTfFj1eMpTHhY2igfx6b9wi8FzqOMfE1UPdxv+yDuo9h2bMw7BNw+k9h1m1O4F38JLzz2/zuKxmHv/4Anr0SqsbCYZ+Hscc590Te+TVEGvO7v0wLHuTtvz7J931P0OKtIu4p6fJXmIqXN466C5lwEnd4f83Y9c9y4u1/5ztPvs/fP9zWf3k0phcs0PfQjtYYrz/9P8R85dRVOuPDdq6jBxgVivGTQ9YxNOCMAjXU33+jQe0YdhQpFRKLZud/48k4PPN1Z/jDKRdDsBy8AZj+dRhxOPzfdfC3H0Jq14tdj7XUwiOfh7m/gmOvhuO+CRM+CZO/CEd9BRpr4Pfn9muwr123hCme1Wza75NoN0M+jt/4Z+aHjqepbDz/4f8tP0vdxevLa/jqQ/NZtqmp3/JoTE9ZoO+heYs/4Ezm8ic5leeWOgFn/fZG3skymMiwQIJbD17HeSNrOaqq/7q3nTi8grmpQ0kufMq5f5BPb/4nbHwXDv8XKKnaOd/rc4Lv0V+Dt/4XnvoyhPtwQ3jtP+HeT0HNfPj8b+Gs28CTUQ2y/xFONdGWxfDklyDeD0+mppIcX/8cG2QkOwYfntsqHj8rxl7M5qHHcXryDV6uuJVDAlu5+fml1rOoGTAs0PeQd/59CMr/tp5KU9ipjin1dl2aLfOlOH9UHRW+PJR4u3D44DjPpU4g2LQGNr2Xvw1vWQJv/NIJ8qOm7rrc44Wz/8OpyvnwL3DXEfD6HdC0ueMFJxmHRAxSyZ3zk3HYvgqWPAP/cyQ8dDbEWuC4b0E8nP25gBGT4dzfwNo3nV8Zqfw+sFTz0XuMYzNvV5zp3IfIkXq8rN//DFaMvZDy6Fae9f07+697nucXWzt7MzDYzdgeSEVaOLr+eV6VY1mfGkb5Zufn+e4C/Z5QXZriHd90EvIQvsVPQfVRfd9oMg5/+iaUDIazbodlf8qe7t2HwBeCE78HH/0V/v4z5+Uvc1rLhBsg2qmqRTxuwHeDfslgpy5+zHHgC+4+X0ecD6218OIP4A+Xw+fuhtCgvh4tkbp1VKz6E0v0AIbsP25n3nqgoeIT/N8BV3D8ouv4n9Q9zPnTh+wY9wCDq6q6X9mYfmSBvgc2vX4/o2lh6+DphLYmWbmlAfBQ6i3so/Dz1tYzODiaVxLHcur8B3nRfzqNFZ/oWz8s/7wLNi+Cf/k9lA7pPn3laKcap7EG6ldD23aItjo3VANlIF5Qt0SvKSfYlw2Fsv2gckzHaprdWfAg+Evg0M/B8uedKp9pl8JpP+79sSZi1D1wEYM0ScvkL1PRiyCfNrL2TdaM/DTJkuF8ZuNLfHznCfxx1Nf4zIVXs39lqMv1VJWtTVGGVwTxepympKmUEk+lrCWP6TMZaPWI06dP1wUL+rmpYA+0xRL4PB4Ca/9O4vGLeD8xnoZDLuLe9SOZ31ABwGPTPsS355p5Z/XUpmG8sdnP64N+RNxfwV+Pf5ILTjikdxt75huweDaMnOLUww9U9avhvYedm7MTT4FjvgEHnubcP8iVKhsfv4bqlY/y+OCruPiEQ7Leb+mNyPb1TN36Ryq0hTdTh/Nq6HQOPPIkDjjwUA6tHszWpgjL1m9jxcqPWLNmFfFwE1W+GCMHhYikPGxsThJNeRkzvIoJ1SNIBQbRlCqhkRLaEh4EOHC/cg7ev4LqqhKGlAWoKg20XyjMvkVE3lXV6VmX5RLoRWQWcBfgBX6nqrd1Wh4Efg8cBdQBF6jqWnfZD4ArgCTwbVV9cXf7GkiBftW2Fr70u7mc5l3ET2O3s4Zqfhz4LtccsI2Xayu5b/1Igp4Uvz/yo0JnlXcbyrnj49H8bEodF6/4Niv3/wxtZ93JjrAyY+JQQv4cS4Xv/NZpSTP8EJj+VaeFzUAWa4V1/4RN70PzZigdBoedC4d82qkKCpR2ve62D9ny5DXsXz+fpwPn8OlTTqbUR94CPYAv0ULZtvcZ3rSUoUmn2WVMvUQJECRGQHr3azCCnxYtpVFLaaaEZi2lmVJaKCXmqyAZqECDVVBaRUXlUEaM2J/9hu9HMlBJIjiIpCeEAl6P4Pd6KAv4GFEZtF8Pe7E+BXoR8QIfAacDNcB84CJVXZaR5pvAEap6lYhcCHxeVS8QkUnAE8AxwCjgZeATqtrlt7uvgT4cS7J6ewsBr4dxQ8vwe4W1dW0s3dTIyMoSJlcPIhJP8eqHW1mysYljJgzhpIOG889V27nrlZVsbAhz1dFDmDm8lef+8jyfTr3OFFawwnMAF4Rv4CuHwoySGrbHfHzrgwOp8iX47ZTCjyPaEPfyjcVOu/7v+p7i277nqNdy/pI8jpXBQ5k+ZQqHHXww/rIhBEorCQW8BLzQWL+dxu0bCda8zYiPn6a0fhkflx3JL/1X4/X5GFmSIqHwwQ4fq5p8BL1KhV8ZEUoxrjzJyJIkZX6lzKeU+pQyr/vXp/g9SnPcQ1Nc8Art8+IpIZ6CWEqIKx3fpyCSFNa1eFnV5COcFIYGUwxxX0ODKfYLpRhVmmJYMEXQqwQ8SlCShLYvwbflPWTrUvdBKy+MmuZUDQ0aRVz8NEZThOs346//iGGNH9CqQR4uuZSy469k8tbn+u8EaYry8EakrY5YWyOtcZwAG/QSDJWS8FeQ8IRIefyoCB5NIu7Lk0ogqTi+ZARfKoo3FcGbjOJLRdFElEQ8hiSj+FNR/KkIIQ0TIrbb7ETVRxsh2ggS1qDzlyAJbykJXxkJXxkpfympQDkaKMcTKMcTqsBXMohASRmB0gpCpRWUlJVTXl5JxaBBhEoqUI8PATxF/KtCVYklUwS9HkhEaGyoY9GqGmrrailJhQkmW2iJJqiPCuXlFRx96ETGjx5NLFDJ1jYYVOKnssQZraglmmBDfRsThpXlXhjrQl8D/QzgZlU9033/A/dgf5GR5kU3zdsi4gO2AMOBGzLTZqbran+9DfQf1DRyzRPvsb6+rb1hh88jXBH4Gxen/oKgeEQRQNBOLxBSlEiCEDF87Gzz3uQfzsqyo7hq2+epTVXws0PWcmCZ07Tv+0vHk1Thzslrepzf/vB63SC2RQOgKaamlnBsfD7jI8vwa24Pa32QGs/s5Mk8kTyFEaEEqlAX8yMC40sijC2JkkRoTXioj/vZGvXTlOif2zwlniTVJTFKPCmaE14aE16aEj6S2n0AqfKEOc77IcfIUg5jDSOknv1oIEAcn6So13JW6miW6QRWD57J2aOjFFtcEk3iTUbxJsOQiNIQThCJxQlpmGAqTFDDBFJRvBrHl4ohqTiSiuFNxQholKBGKSFCKT17ojupQhIPKTykxEsKT/v79vl4drkL4vwXdjiCDn+c/1pAFQUEcZYppNxE6V4ynP9/xYPu7DnDvfnvAUTUvdeeOc9No846kpkjVUQ6vUcpIYq/h7/IwhogQoCUeFCEhDqfy/CKEgJ+H3ziLKdpcS/0NdCfB8xS1a+5778MHKuq12SkWeKmqXHffwwcC9wMzFXVR9359wP/p6p/6LSPK4Er3bcHAyvY9wwDthc6EwVgx71vsePuP+NUdXi2BbkUx7KVdTpfHbpKk8u6qOq9wL055KVoiciCrq7GxcyOe99ix10YuTwVUgOMyXg/GujcCXd7GrfqphKoz3FdY4wx/SiXQD8fOEhEJohIALgQmNMpzRzgMnf6POBVdeqE5gAXikhQRCYABwHz8pN1Y4wxuei26kZVEyJyDfAiTvPKB1R1qYjcCixQ1TnA/cAjIrIKpyR/obvuUhF5ClgGJIBv7a7FzT5uX626suPet9hxF8CAe2DKGGNMflmnZsYYU+Qs0BtjTJGzQF9gIjJLRFaIyCoRuaHQ+elPIrJWRD4QkYUissCdN0REXhKRle7fwYXOZz6IyAMiss19xiQ9L+uxiuN/3O/AYhGZVric900Xx32ziGx0z/tCETk7Y9kP3ONeISJnFibXfSciY0Tk7yKyXESWisi/ufMHxDm3QF9AbvcS9wBnAZOAi9xuI4rZyao6NaNN8Q3AK6p6EPCK+74YPATM6jSvq2M9C6dF2kE4Dw7+eg/lsT88xK7HDXCne96nquoLAO53/ULgMHedX7n/E3ujBPA9VT0UOA74lnt8A+KcW6AvrGOAVaq6WlVjwJPAOQXO0552DvCwO/0wcG4B85I3qvoGTgu0TF0d6znA79UxF6gSkZF7Jqf51cVxd+Uc4ElVjarqGmAVzv/EXkdVN6vqe+50M7AcqGaAnHML9IVVDWzIeF/jzitWCvxNRN51u70AGKGqm8H5ZwH2K1ju+l9Xx7ovfA+ucasoHsionivK4xaR8cCRwDsMkHNugb6wcuoiooicoKrTcH62fktETip0hgaIYv8e/BqYCEwFNgP/6c4vuuMWkXLgj8B3VHV3I8Tv0WO3QF9Y+1QXEaq6yf27DXgW52f61vRPVvfvtsLlsN91daxF/T1Q1a2qmlTVFHAfO6tniuq4RcSPE+QfU9Vn3NkD4pxboC+sXLqXKAoiUiYiFelp4AxgCR27z7gM6GJw2qLQ1bHOAS51W2IcBzSmf+4Xg051z5/HOe9QRF2kiIjg9BCwXFX/K2PRwDjnqmqvAr6As3EGdvkYuLHQ+enH4zwAWOS+lqaPFRiK0xphpft3SKHzmqfjfQKnmiKOU3q7oqtjxfkZf4/7HfgAmF7o/Of5uB9xj2sxToAbmZH+Rve4VwBnFTr/fTjumThVL4uBhe7r7IFyzq0LBGOMKXJWdWOMMUXOAr0xxhQ5C/TGGFPkLNAbY0yRs0BvjDFFzgK9McYUOQv0Zo8TkfGZ3dgOZG7XysPc6bcKnZ9cicjUzO6Ae7mNf89XfkxhWaA3A95A6bpWVY8vdB56YCrOAzt9YYG+SFigNz3mdmfwFxFZJCJLROQCETlaRN5y580TkQq35P6miLznvnYJlF2lEZFPuQM5PI7z5GBXebnU7RVxkYg84s4bJyKvuPNfEZGx7vyHROS8jHVbMvb1hog8KyLLROQ3IrLL/0an9K+JyB9E5EMRecx9BB4ROdud9w93YIk/7ybv5SLyoDiDsSwWkS+68y9y5y0Rkdsz9y8iP3OPda6IjHDnn++mXeQeRwC4FbhAnIE+LhCRY9zz877792B33a+IyDMi8ldxBse4w51/G1Dirv9YV8dg9hKFfnTYXnvfC/gicF/G+0pgNXC0+34Q4ANKgZA77yBggTs9HljiTneV5lNAKzBhN/k4DOfR+WHu+/Tj5c8Dl7nTXwWec6cfAs7LWL8lY18RnG4avMBL6XTA2oztZ6ZvxOmIygO8jfMIfAin69kJbrongD/vJv+3A/+d8X4wMApYDwx3P8NXgXPd5Qp81p2+A/ihO/0BUO1OV7l/vwLcnbHtQYDPnT4N+GNGutXuOQwB64Axmcdrr73/ZSV60xsfAKeJyO0iciIwFtisqvMBVLVJVROAH7hPRD4AnsYZRauz3aWZp86AFF05BfiDqm5395se8GIG8Lg7/QhOEO7OPHUGgEniBOju1pmnqjXq9Mi4EOfidQiwOiPPT3SzjdNw+jvBzf8O4GjgNVWtdT/Dx4B0d84xIP0L4V13nwD/BB4Ska/jXKiyqQSedu+N3IlzkUx7RVUbVTUCLAPG/f/27t01qiAM4/DvlSAWBvFSpVSwEEQhaEoFSwWxUUREUwiiogg2NmlUIihYiIKx9Y+QQFgjiZoU4x4hiwAAAiVJREFUEgMB0UIbCYIW4p0on8XMwSWevZlg3M37NHsuczvFzpkzA980aLe1ma6lboC1n4h4IamXNAc8CAxTHkv7PPAW2EYa+X5rMc3nBk1RjXr/aHL+/ZHrKKINrixJU+t8vu9Vxz9J/6WyGOP1lLW/XhlzEVGkL+okIk5K6gP2AlOStpfkvQRUIuKA0sYYD6rulT2LdRCP6K1lknqALxFxD7hO2iOzR9KOfL9bUhdpFDmbR71HKR9tNpOmlhHgoKT1ud51+fojUshngCPAWD5+DfTm4/2kr4nCTqVw0SuAQ1V5WvEc2Jg7UnI59QwDZ4oTpZ2XJoBdkjbkRejDwGi9QiRtioiJiBgA3pHinH8EuquSrQHe5OPjzTwMMKcUY93anDt6+xtbgUlJU6QwswOkTu2mpGekOe5VwG3gmKQnwGbKR+jNpCkVETPAFWA011vEAT8L9EuaJr08zuXrd0md6CTQN6+ux8BVUqz0V6SNUVoSEV+BU8B9SWOkL5UPdbJcBtYWC6mkjdNngYtAhRTS+WlENIrRf61YvAUe5nwVYEuxGEua0x+UNE7zL9MhYNqLse3PYYpt2ZO0G7gQEfsWoazVEfEpTw3dAl5GxI2Flmu2EB7Rmy2uE/lLZ4Y0XXJnidtj5hG9/f/yHPxIya09EfH+X7enVZL6+T19VBiPiNNL0R5bftzRm5l1OE/dmJl1OHf0ZmYdzh29mVmHc0dvZtbhfgGnXKMfyHed4gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Train_scalar_coupling_constant\n",
      "count                    4.658147e+06\n",
      "mean                     1.592165e+01\n",
      "std                      3.494198e+01\n",
      "min                     -3.621860e+01\n",
      "25%                     -2.549780e-01\n",
      "50%                      2.281130e+00\n",
      "75%                      7.390655e+00\n",
      "max                      2.048800e+02\n",
      "       Train_subsample_scalar_coupling_constant\n",
      "count                             300000.000000\n",
      "mean                                  18.066605\n",
      "std                                   34.188050\n",
      "min                                  -26.899000\n",
      "25%                                   -0.095366\n",
      "50%                                    2.507215\n",
      "75%                                   29.319300\n",
      "max                                  202.129000\n"
     ]
    }
   ],
   "source": [
    "train_subsampled = subsampling(train, 300000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of the distributions of scalar coupling constant in the whole training set and the subsampled training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_subsampled, y_subsampled = preprocessing_features(train_subsampled)\n",
    "y_subsampled = y_subsampled.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation of model 1 on subsampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def model_1_subsampled():\n",
    "    \"\"\" Baseline model + 1 hidden layer + dropout\"\"\"\n",
    "    K.backend()\n",
    "    model = Sequential()\n",
    "    \n",
    "    #input layer\n",
    "    model.add(Dense(int(X_subsampled.shape[1]), input_dim = int(X_subsampled.shape[1])))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    #hidden layer\n",
    "    model.add(Dense(int(X_subsampled.shape[1]/2)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    \n",
    "    #output layer\n",
    "    model.add(Dense(1))\n",
    "    adam = optimizers.Adam()\n",
    "    model.compile(loss = 'mean_squared_error', optimizer= adam)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 31s 154us/step - loss: 32.2744\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 31s 154us/step - loss: 13.7282\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 31s 155us/step - loss: 13.1197\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 31s 154us/step - loss: 12.6416\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 31s 154us/step - loss: 12.0329\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 31s 154us/step - loss: 11.3974\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 31s 154us/step - loss: 10.8701\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 10.4468\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 31s 154us/step - loss: 10.0309\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 9.6223\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 30s 151us/step - loss: 9.2551\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 8.9703\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 8.6490\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 30s 152us/step - loss: 8.4000\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 8.2816\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 8.0613\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 31s 154us/step - loss: 7.9309\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 7.8106\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 7.7688\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 7.6796\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 31s 154us/step - loss: 7.5888\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 7.5229\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 7.4581\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 7.4295\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 7.3149\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 7.2803\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 7.2916\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 7.2475\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 7.1888\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 7.1499\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 7.1081\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 7.1007\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 7.0366\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 7.0506\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 7.0255\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 7.0062\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 30s 152us/step - loss: 6.9715\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 6.9480\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 6.9128\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 6.8720\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 6.8597\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 6.8943\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 6.8094\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 31s 154us/step - loss: 6.7580\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 30s 152us/step - loss: 6.8023\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 6.7039\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 6.6670\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 30s 152us/step - loss: 6.6690\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 6.6396\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 6.5995\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 31s 154us/step - loss: 113.0184\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 30s 151us/step - loss: 36.0623\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 30s 149us/step - loss: 32.5389\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 30s 150us/step - loss: 31.6768\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 30s 151us/step - loss: 31.2221\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 30s 150us/step - loss: 30.1122\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 30s 151us/step - loss: 29.4001\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 30s 150us/step - loss: 28.7773\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 30s 150us/step - loss: 28.2102\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 30s 150us/step - loss: 27.1712\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 30s 150us/step - loss: 26.4902\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 30s 150us/step - loss: 25.8721\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 30s 150us/step - loss: 25.7189\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 30s 150us/step - loss: 25.3944\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 30s 150us/step - loss: 25.1803\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 30s 150us/step - loss: 25.0076\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 30s 148us/step - loss: 24.7636\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 30s 148us/step - loss: 24.5936\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 30s 149us/step - loss: 24.4376\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 30s 149us/step - loss: 24.2172\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 30s 148us/step - loss: 24.2678\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 29s 147us/step - loss: 24.1130\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 29s 147us/step - loss: 23.9031\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 30s 149us/step - loss: 23.7743\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 29s 147us/step - loss: 23.7298\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 29s 146us/step - loss: 23.5881\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 29s 147us/step - loss: 23.5061\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 29s 147us/step - loss: 23.3882\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 29s 146us/step - loss: 23.3638\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 29s 146us/step - loss: 23.1958\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 29s 145us/step - loss: 23.1121\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 29s 145us/step - loss: 23.0409\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 29s 146us/step - loss: 22.9529\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 29s 143us/step - loss: 22.9550\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 28s 142us/step - loss: 22.8099\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 29s 144us/step - loss: 22.7628\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 29s 146us/step - loss: 22.7386\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 30s 148us/step - loss: 22.7281\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 30s 149us/step - loss: 22.7144\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 30s 151us/step - loss: 22.5844\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 30s 151us/step - loss: 22.5285\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 30s 152us/step - loss: 22.4012\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 30s 152us/step - loss: 22.2590\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 30s 152us/step - loss: 22.3412\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 22.3568\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 30s 151us/step - loss: 22.2837\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 30s 150us/step - loss: 22.1878\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 30s 150us/step - loss: 22.1354\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 30s 151us/step - loss: 21.9441\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 30s 151us/step - loss: 21.9190\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 31s 157us/step - loss: 122.3100\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 31s 154us/step - loss: 36.7289\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 30s 152us/step - loss: 33.0701\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 30s 151us/step - loss: 31.9958\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 30.9936\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 30.0191\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 31s 154us/step - loss: 29.4403\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 28.6380\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 30s 152us/step - loss: 28.3807\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 30s 150us/step - loss: 27.8641\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 30s 150us/step - loss: 27.6795\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 30s 148us/step - loss: 27.3505\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 30s 150us/step - loss: 27.1857\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 30s 150us/step - loss: 26.9740\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 30s 150us/step - loss: 26.5806\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 30s 151us/step - loss: 26.5130\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 30s 151us/step - loss: 26.3419\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 30s 151us/step - loss: 26.1550\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 30s 152us/step - loss: 26.0050\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 29s 147us/step - loss: 25.9005\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 29s 145us/step - loss: 25.8351\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 29s 145us/step - loss: 25.7270\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 29s 144us/step - loss: 25.5925\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 29s 146us/step - loss: 25.5398\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 30s 152us/step - loss: 25.5155\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 30s 152us/step - loss: 25.2764\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 30s 151us/step - loss: 25.2445\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 30s 152us/step - loss: 25.1752\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 30s 151us/step - loss: 25.1478\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 30s 152us/step - loss: 25.0255\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 30s 152us/step - loss: 25.0086\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 24.9392\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 30s 152us/step - loss: 24.8954\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 31s 153us/step - loss: 24.8239\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 30s 152us/step - loss: 24.8100\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 30s 152us/step - loss: 24.8298\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 30s 149us/step - loss: 24.7120\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 30s 148us/step - loss: 24.6004\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 29s 146us/step - loss: 24.6837\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 30s 151us/step - loss: 24.4764\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 30s 149us/step - loss: 24.4972\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 30s 152us/step - loss: 24.4481\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 30s 152us/step - loss: 24.3218\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 30s 151us/step - loss: 24.1570\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 30s 152us/step - loss: 24.2686\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 30s 151us/step - loss: 24.2063\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 30s 150us/step - loss: 24.2221\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 30s 151us/step - loss: 24.0789\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 30s 150us/step - loss: 23.9985\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 30s 151us/step - loss: 24.0096\n"
     ]
    }
   ],
   "source": [
    "model_1_score_subsampled = evaluation(model_1_subsampled, X_subsampled, y_subsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1532.407646</td>\n",
       "      <td>6.323515</td>\n",
       "      <td>-5544.947285</td>\n",
       "      <td>-46.531128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1488.996960</td>\n",
       "      <td>7.011984</td>\n",
       "      <td>-11.016185</td>\n",
       "      <td>-2.179924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1507.588302</td>\n",
       "      <td>7.084641</td>\n",
       "      <td>-544.430985</td>\n",
       "      <td>-15.630765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time  test_neg_mean_squared_error  \\\n",
       "0  1532.407646    6.323515                 -5544.947285   \n",
       "1  1488.996960    7.011984                   -11.016185   \n",
       "2  1507.588302    7.084641                  -544.430985   \n",
       "\n",
       "   test_neg_mean_absolute_error  \n",
       "0                    -46.531128  \n",
       "1                     -2.179924  \n",
       "2                    -15.630765  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_score_subsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large difference between MSE on the training and test folds; model is overfitting and there is a lot of fluctuation between folds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search of kernel initializers and number of neurons in the hidden layer on the subsampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def model_2_subsampled(kernel_init_1, kernel_init_2, kernel_init_3):\n",
    "    K.backend()\n",
    "    model = Sequential()\n",
    "    \n",
    "    #input layer\n",
    "    model.add(Dense(int(X_subsampled.shape[1]), input_dim = int(X_subsampled.shape[1]),\n",
    "                    kernel_initializer = kernel_init_1))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    #hidden layer\n",
    "    model.add(Dense(int(X_subsampled.shape[1]/2), kernel_initializer = kernel_init_2))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    \n",
    "    #output layer\n",
    "    model.add(Dense(1, kernel_initializer = kernel_init_3))\n",
    "    adam = optimizers.Adam()\n",
    "    model.compile(loss = 'mean_squared_error', optimizer= adam)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 31.2294\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 43s 216us/step - loss: 14.4507\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 43s 216us/step - loss: 13.6971\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 43s 216us/step - loss: 13.1604\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 12.5746\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 11.8828\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 44s 222us/step - loss: 11.3099\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 10.9363\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 10.6166\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 45s 223us/step - loss: 10.2929\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 9.9032\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 43s 217us/step - loss: 9.5274\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 43s 217us/step - loss: 9.1623\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 43s 215us/step - loss: 8.8776\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 43s 214us/step - loss: 8.5830\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 43s 215us/step - loss: 8.4053\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 43s 217us/step - loss: 8.2945\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 43s 216us/step - loss: 8.1563\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 43s 216us/step - loss: 8.0523\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 43s 214us/step - loss: 7.9813\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 43s 214us/step - loss: 7.9413\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 43s 214us/step - loss: 7.8430\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 43s 214us/step - loss: 7.7827\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 43s 215us/step - loss: 7.6908\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 43s 215us/step - loss: 7.6503\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 43s 213us/step - loss: 7.5985\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 43s 216us/step - loss: 7.4804\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 43s 215us/step - loss: 7.4144\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 43s 214us/step - loss: 7.4101\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 43s 215us/step - loss: 7.3628\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 43s 214us/step - loss: 7.2886\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 43s 214us/step - loss: 7.2187\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 43s 214us/step - loss: 7.1847\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 43s 214us/step - loss: 7.1205\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 43s 215us/step - loss: 7.1054\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 43s 214us/step - loss: 7.0158\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 43s 215us/step - loss: 6.9706\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 43s 214us/step - loss: 6.9793\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 43s 214us/step - loss: 6.8547\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 43s 214us/step - loss: 6.8740\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 43s 215us/step - loss: 6.8110\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 43s 215us/step - loss: 6.8052\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 43s 214us/step - loss: 6.7750\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 43s 215us/step - loss: 6.7285\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 43s 214us/step - loss: 6.6884\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 43s 213us/step - loss: 6.6617\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 43s 214us/step - loss: 6.6817\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 43s 214us/step - loss: 6.6656\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 43s 215us/step - loss: 6.6129\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 43s 214us/step - loss: 6.5481\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 126.3849\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 43s 214us/step - loss: 36.0032\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 43s 213us/step - loss: 32.1893\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 43s 213us/step - loss: 31.4227\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 43s 213us/step - loss: 30.5126\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 43s 213us/step - loss: 29.4308\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 43s 213us/step - loss: 28.5930\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 43s 213us/step - loss: 28.0461\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 43s 213us/step - loss: 27.1915\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 43s 213us/step - loss: 26.7819\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 43s 213us/step - loss: 26.2009\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 43s 213us/step - loss: 25.7961\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 43s 213us/step - loss: 25.3588\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 43s 213us/step - loss: 25.0992\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 43s 213us/step - loss: 24.8931\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 43s 213us/step - loss: 24.7566\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 42s 212us/step - loss: 24.5607\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 43s 213us/step - loss: 24.4635\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 42s 212us/step - loss: 24.3273\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 42s 212us/step - loss: 24.2453\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 42s 212us/step - loss: 24.0486\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 42s 212us/step - loss: 23.9055\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 42s 212us/step - loss: 23.8445\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 43s 213us/step - loss: 23.7469\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 43s 213us/step - loss: 23.6202\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 43s 213us/step - loss: 23.6477\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 42s 212us/step - loss: 23.5233\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 42s 212us/step - loss: 23.4972\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 42s 212us/step - loss: 23.3569\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 42s 212us/step - loss: 23.3333\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 43s 213us/step - loss: 23.2787\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 43s 213us/step - loss: 23.2337\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 43s 213us/step - loss: 23.0489\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 42s 212us/step - loss: 23.0499\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 42s 212us/step - loss: 22.9161\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 42s 212us/step - loss: 22.9723\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 42s 212us/step - loss: 22.9359\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 42s 212us/step - loss: 22.7909\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 42s 212us/step - loss: 22.7280\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 43s 215us/step - loss: 22.6419\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 43s 216us/step - loss: 22.5600\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 43s 216us/step - loss: 22.5628\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 43s 216us/step - loss: 22.4746\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 43s 215us/step - loss: 22.5415\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 43s 216us/step - loss: 22.4109\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 43s 214us/step - loss: 22.2328\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 43s 215us/step - loss: 22.2186\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 43s 216us/step - loss: 22.2245\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 43s 215us/step - loss: 22.1840\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 43s 215us/step - loss: 22.1253\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 117.0072\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 36.8799\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 33.2180\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 32.0258\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 31.1417\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 30.4715\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 29.6100\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 29.1311\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 28.5888\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 28.0535\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 27.8416\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 27.3677\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 27.2871\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 26.9546\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 26.8046\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 26.6097\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 26.5589\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 26.3571\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 26.2998\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 26.1275\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 25.9482\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 25.9002\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 25.8010\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 25.6802\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 25.6066\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 25.5576\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 25.3548\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 25.2592\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 25.2144\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 25.2255\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 25.0690\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 24.9246\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 24.8797\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 24.8542\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 24.7029\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 24.6777\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 24.5958\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 24.5466\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 24.4850\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 24.3183\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 24.2497\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 43s 217us/step - loss: 24.1632\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 24.0870\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 24.0609\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 23.9985\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 23.9432\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 23.9133\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 23.8823\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 23.7627\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 23.7272\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 29.6482\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 43s 217us/step - loss: 14.2169\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 13.3553\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 12.7474\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 43s 217us/step - loss: 12.2900\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 11.6536\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 43s 217us/step - loss: 11.0818\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 10.6799\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 10.2949\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 9.9490\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 9.6038\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 43s 217us/step - loss: 9.2971\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 9.0680\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 8.7862\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 43s 217us/step - loss: 8.5615\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 8.4305\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 43s 217us/step - loss: 8.1943\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 43s 217us/step - loss: 8.0886\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 43s 217us/step - loss: 7.9649\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 7.9166\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 7.7934\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 43s 217us/step - loss: 7.7947\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 7.7325\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 43s 217us/step - loss: 7.6265\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 7.5348\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 43s 217us/step - loss: 7.4462\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 43s 217us/step - loss: 7.4181\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 7.3293\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 44s 219us/step - loss: 7.3505\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 7.3215\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 7.2555\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 7.2170\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 7.2060\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 7.1862\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 7.1456\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 7.0847\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 7.0641\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 7.0699\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 7.0107\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 6.9599\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 6.9503\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 6.9507\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 6.8856\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 6.8649\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 6.8506\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 6.8096\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 6.7824\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 6.7688\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 6.7298\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 6.7059\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 124.4728\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 36.6644\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 32.9245\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 31.7089\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 31.0418\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 30.1149\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 29.5352\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 28.6735\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 27.9025\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 27.1269\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 26.5800\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 26.0518\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 25.6775\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 25.3304\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 25.2634\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 24.8991\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 24.8932\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 24.6314\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 24.5684\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 24.3742\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 24.2263\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 43s 217us/step - loss: 24.0191\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 23.9573\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 23.8280\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 23.6753\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 23.5811\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 43s 217us/step - loss: 23.5508\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 23.3979\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 23.2251\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 23.1746\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 23.0407\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 22.8141\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 22.7941\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 22.8118\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 22.6334\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 22.6121\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 22.5236\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 22.5126\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 43s 217us/step - loss: 22.4749\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 22.4066\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 43s 217us/step - loss: 22.2895\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 22.3596\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 22.1325\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 22.1774\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 22.1595\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 22.1292\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 43s 217us/step - loss: 22.0628\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 21.9475\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 21.9619\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 43s 217us/step - loss: 21.9318\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 134.6400\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 36.6090\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 32.7306\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 31.8279\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 30.9491\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 30.2961\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 29.7167\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 28.9540\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 28.5443\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 28.1023\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 27.9308\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 27.6621\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 27.3737\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 27.2547\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 27.2219\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 26.8582\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 26.7374\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 26.6760\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 26.3579\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 26.2068\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 26.0992\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 25.9805\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 25.7701\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 25.6420\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 25.5505\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 25.4947\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 25.3217\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 25.2162\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 25.0893\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 25.0763\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 24.9442\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 24.9127\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 24.7358\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 24.6701\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 24.6049\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 24.3643\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 24.3497\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 24.2331\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 24.2042\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 24.0078\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 23.9719\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 23.8929\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 23.7182\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 23.6671\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 23.5976\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 23.6106\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 23.4757\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 23.4431\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 23.3642\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 23.2796\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 48s 239us/step - loss: 30.1810\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 45s 223us/step - loss: 13.9022\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 13.1343\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 12.6619\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 12.0944\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 11.5266\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 10.9539\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 10.5190\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 10.1684\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 9.8447\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 9.5034\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 44s 222us/step - loss: 9.1940\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 8.8918\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 8.6116\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 44s 222us/step - loss: 8.3522\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 8.1732\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 8.0086\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 7.8399\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 7.7670\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 7.7105\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 44s 222us/step - loss: 7.6257\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 7.5817\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 7.5052\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 7.4471\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 7.3883\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 7.3376\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 7.2805\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 7.2373\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 7.2035\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 7.1552\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 7.0961\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 7.0649\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 7.0057\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 7.0194\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 6.9839\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 6.9590\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 6.9166\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 6.8247\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 6.8058\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 44s 218us/step - loss: 6.7511\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 6.7171\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 6.6737\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 6.6355\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 6.6098\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 6.5939\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 6.5313\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 6.5523\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 6.5444\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 6.4765\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 6.4621\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 48s 238us/step - loss: 132.4016\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 40.0975\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 33.4414\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 31.7029\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 30.9470\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 30.5916\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 44s 222us/step - loss: 29.9652\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 44s 222us/step - loss: 29.1596\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 44s 222us/step - loss: 28.0605\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 45s 223us/step - loss: 27.2156\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 44s 222us/step - loss: 26.4462\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 25.9548\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 44s 222us/step - loss: 25.4955\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 44s 222us/step - loss: 25.1657\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 44s 222us/step - loss: 24.8439\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 24.5765\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 44s 222us/step - loss: 24.4149\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 44s 222us/step - loss: 24.1596\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 45s 223us/step - loss: 24.0528\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 23.8736\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 44s 222us/step - loss: 23.7240\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 44s 222us/step - loss: 23.4896\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 23.5155\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 44s 222us/step - loss: 23.3500\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 23.2058\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 23.1541\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 22.9112\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 22.9279\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 22.8578\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 22.7301\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 22.6658\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 44s 222us/step - loss: 22.5506\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 44s 222us/step - loss: 22.5610\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 22.4719\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 22.2580\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 22.1703\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 45s 223us/step - loss: 22.1567\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 22.0329\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 44s 222us/step - loss: 21.9290\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 21.9667\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 21.8852\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 44s 222us/step - loss: 21.8232\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 21.6217\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 21.5766\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 21.7243\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 21.5095\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 21.4452\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 21.3827\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 44s 222us/step - loss: 21.3730\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 21.2976\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 48s 239us/step - loss: 137.7407\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 35.7031\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 32.0188\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 31.1981\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 30.4586\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 29.8158\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 29.1924\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 28.8256\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 28.5007\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 28.1511\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 27.7477\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 27.3563\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 27.0644\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 26.8180\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 26.6602\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 26.4600\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 26.3233\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 26.1566\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 26.0343\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 25.8975\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 25.9747\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 25.7606\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 25.7887\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 25.5611\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 25.5768\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 25.4400\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 25.4278\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 25.3274\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 25.2504\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 25.3219\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 25.1009\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 25.1012\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 25.0177\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 25.0008\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 24.8815\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 24.7997\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 24.7639\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 24.6918\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 24.6133\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 24.6317\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 24.6026\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 44s 220us/step - loss: 24.4970\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 24.4458\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 24.4005\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 44s 219us/step - loss: 24.3567\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 24.2559\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 44s 222us/step - loss: 24.2406\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 44s 222us/step - loss: 24.1424\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 24.0919\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 44s 221us/step - loss: 24.0943\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 49s 243us/step - loss: 30.2798\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 13.7502\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 13.2492\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 12.8517\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 12.4351\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 12.0839\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 11.6414\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 11.2335\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 10.9129\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 10.6180\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 10.3324\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 9.9513\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 9.6341\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 9.3122\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 9.0203\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 8.8183\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 8.6154\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 8.4618\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 8.3398\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 8.2047\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 8.1028\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 8.0447\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 7.9097\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 7.8009\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 7.7328\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 7.6166\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 7.5430\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 7.5161\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 7.4583\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 7.3967\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 45s 223us/step - loss: 7.3830\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 7.3317\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 7.2674\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 7.2377\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 7.1917\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 7.1569\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 7.0854\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 7.0285\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 7.0063\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 6.9139\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 6.9226\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 6.8686\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 6.8064\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 45s 223us/step - loss: 6.7653\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 45s 223us/step - loss: 6.7848\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 6.6851\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 6.6676\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 6.5998\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 6.5984\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 6.5745\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 49s 243us/step - loss: 117.8853\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 35.5964\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 32.4985\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 31.5820\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 30.8954\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 30.1740\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 29.2031\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 28.2920\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 27.9222\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 26.8957\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 26.5258\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 26.0196\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 25.6825\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 25.2224\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 25.1205\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 24.7853\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 24.7618\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 24.4626\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 45s 223us/step - loss: 24.3231\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 24.2608\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 24.0942\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 23.9449\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 23.8631\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 23.7387\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 23.6442\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 23.5160\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 45s 223us/step - loss: 23.5267\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 45s 223us/step - loss: 23.4183\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 23.2031\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 23.1942\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 45s 223us/step - loss: 23.1670\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 45s 223us/step - loss: 23.0544\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 44s 222us/step - loss: 23.0155\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 22.9372\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 45s 225us/step - loss: 23.0559\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 22.8607\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 22.7088\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 22.5848\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 22.5558\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 22.6020\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 22.5279\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 22.4455\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 22.3579\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 22.4103\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 22.3680\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 22.3556\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 22.3260\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 22.2086\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 22.1536\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 22.0641\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 49s 244us/step - loss: 112.3593\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 36.7481\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 33.1618\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 31.7217\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 31.0301\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 30.0760\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 29.5659\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 28.9953\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 28.2794\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 28.0649\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 27.6285\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 27.3740\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 27.3571\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 27.0211\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 26.6607\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 26.3728\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 26.4583\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 26.1597\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 25.9720\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 25.8994\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 25.7827\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 25.7203\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 25.5867\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 25.5448\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 25.4885\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 25.3349\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 25.1942\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 25.1135\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 25.0255\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 24.9966\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 24.8927\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 24.9012\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 24.8142\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 24.6738\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 24.6915\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 24.5263\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 24.5709\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 24.5145\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 24.5082\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 24.4465\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 24.3278\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 24.2867\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 24.2519\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 24.2792\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 24.1191\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 45s 224us/step - loss: 24.0968\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 24.1236\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 24.0402\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 23.9765\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 23.8698\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 51s 254us/step - loss: 31.0081\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 14.3121\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 13.6214\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 12.9245\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 12.3383\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 11.6678\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 11.2481\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 10.6785\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 10.2203\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 9.8502\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 9.5194\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 9.2595\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 9.0281\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 8.7909\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 8.5795\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 8.4249\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 8.1756\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 7.9959\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 7.8751\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 7.7535\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 7.6395\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 7.5148\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 7.4384\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 7.3684\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 7.3097\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 7.2293\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 7.2025\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 7.1501\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 7.1004\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 7.0822\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 7.0082\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 6.9787\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 6.8898\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 6.8501\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 6.8282\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 6.8043\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 6.7858\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 6.7388\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 6.7382\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 6.7138\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 6.6429\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 6.6112\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 6.5990\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 6.5802\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 6.5121\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 6.5449\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 6.4708\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 6.4772\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 6.4374\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 6.4033\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 50s 249us/step - loss: 147.6086\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 44.6698\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 38.1403\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 34.2565\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 32.8797\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 31.7875\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 31.0591\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 30.4422\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 29.7472\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 29.3293\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 28.7513\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 28.1784\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 27.8124\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 27.2205\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 26.8460\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 26.5400\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 26.2220\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 25.8107\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 25.2604\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 24.8414\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 24.5085\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 24.2775\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 24.1409\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 23.9588\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 23.9607\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 23.7334\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 23.7093\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 23.5875\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 23.5296\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 23.3568\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 23.2809\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 23.2448\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 23.2202\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 23.0841\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 23.0509\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 22.9349\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 22.9166\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 22.9061\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 22.7371\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 22.6310\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 22.6655\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 22.5939\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 22.5729\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 22.5542\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 22.5796\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 22.5391\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 22.3145\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 22.3297\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 22.3259\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 22.1956\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 49s 245us/step - loss: 134.4563\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 37.1057\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 33.2323\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 45s 225us/step - loss: 32.6774\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 31.5470\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 31.1173\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 30.6840\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 30.5674\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 29.9571\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 29.8521\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 29.4200\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 28.7595\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 46s 228us/step - loss: 28.4574\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 28.0284\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 27.6467\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 27.3912\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 27.1019\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 26.9736\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 26.7395\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 26.6643\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 26.5043\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 26.3840\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 26.1757\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 26.0086\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 26.0957\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 25.8259\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 25.8825\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 25.6730\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 25.7439\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 25.5901\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 25.4722\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 25.4545\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 25.3861\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 25.3222\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 25.2507\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 25.2334\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 25.1169\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 25.0992\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 25.0453\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 25.0257\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 24.9808\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 24.8910\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 24.8341\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 24.8200\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 24.7312\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 24.6989\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 24.6621\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 24.5663\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 24.5822\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 45s 227us/step - loss: 24.4670\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 50s 249us/step - loss: 32.0082\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 13.9280\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 13.4415\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 13.0042\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 12.4548\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 11.9198\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 11.4770\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 11.0380\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 10.6363\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 10.2991\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 9.9681\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 9.6289\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 9.2557\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 8.9667\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 8.7119\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 8.5198\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 8.3224\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 8.1572\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 8.0281\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 7.8985\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 7.8228\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 7.7133\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 7.5961\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 7.5242\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 7.4328\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 7.4101\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 7.3164\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 7.2724\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 7.2437\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 7.1740\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 7.1266\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 7.1171\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 7.0344\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 6.9971\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 6.9495\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 6.9082\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 6.8964\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 6.8333\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 6.8196\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 6.8033\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 6.7534\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 6.7225\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 6.7043\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 6.6412\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 6.6281\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 6.5750\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 6.6363\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 6.5562\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 6.5453\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 6.4856\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 50s 251us/step - loss: 138.8346\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 39.4030\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 33.5804\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 31.5805\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 30.4800\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 29.4772\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 28.4177\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 27.5283\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 26.8672\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 26.1649\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 25.7787\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 25.3083\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 25.0461\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 24.9018\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 24.5421\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 24.5212\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 24.3259\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 24.2200\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 24.1426\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 23.8575\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 23.7269\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 23.6571\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 23.4955\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 23.4194\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 23.1935\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 23.0438\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 22.9611\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 22.8789\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 22.8245\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 22.7485\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 22.5986\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 22.6029\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 22.5333\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 22.3763\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 22.3870\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 22.2713\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 22.3110\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 22.1989\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 22.1384\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 22.1072\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 22.0264\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 22.0821\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 22.0094\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 21.8985\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 21.8453\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 21.7749\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 21.7351\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 21.6687\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 21.5923\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 21.6087\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 50s 252us/step - loss: 145.6214\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 41.3982\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 34.3872\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 32.2823\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 31.1563\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 30.4795\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 29.9890\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 29.6472\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 28.9519\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 28.4091\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 28.0438\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 27.7581\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 27.4906\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 27.1659\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 27.0211\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 26.7423\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 26.4637\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 26.2797\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 26.1313\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 25.9213\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 25.8675\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 25.6370\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 25.6252\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 25.3792\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 25.4033\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 25.2439\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 25.3374\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 25.1995\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 25.0377\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 46s 228us/step - loss: 24.9298\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 24.8890\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 24.7737\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 24.6635\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 24.6977\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 24.5992\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 24.3988\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 24.3695\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 24.2406\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 24.2839\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 24.0796\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 46s 231us/step - loss: 24.1558\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 23.9487\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 23.9633\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 23.7676\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 23.6895\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 46s 231us/step - loss: 23.6390\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 23.6257\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 23.5318\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 23.3834\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 23.2964\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 51s 254us/step - loss: 32.1293\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 14.6291\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 13.6435\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 13.1128\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 12.4615\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 11.9040\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 11.4947\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 11.2482\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 11.0274\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 10.8739\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 10.6255\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 10.4167\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 10.2276\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 9.9871\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 9.7030\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 9.4193\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 9.2349\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 8.9746\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 8.7650\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 8.5854\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 8.4140\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 8.2322\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 8.0950\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 7.9802\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 7.8465\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 7.7316\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 7.6007\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 7.5423\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 7.4232\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 48s 238us/step - loss: 7.3770\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 7.3208\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 7.2754\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 7.1621\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 7.0739\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 7.0170\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 6.9887\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 6.9329\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 6.8998\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 6.8700\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 6.7679\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 6.7899\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 6.7117\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 6.6589\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 6.6628\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 6.6559\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 6.5968\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 6.5075\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 6.4957\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 6.4818\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 6.4539\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 51s 256us/step - loss: 112.6899\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 36.5257\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 33.0234\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 31.5892\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 30.6088\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 30.1779\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 46s 229us/step - loss: 29.4507\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 49s 245us/step - loss: 28.5678\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 49s 246us/step - loss: 27.8058\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 48s 239us/step - loss: 27.0476\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 26.2811\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 25.8788\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 25.5332\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 25.3004\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 24.9952\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 24.6975\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 24.5478\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 48s 239us/step - loss: 24.3739\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 24.2552\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 24.1311\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 23.9360\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 23.8390\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 23.6809\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 23.6279\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 23.3964\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 23.4343\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 23.2239\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 23.2014\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 23.1538\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 22.9343\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 22.9008\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 22.8552\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 22.7313\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 22.7036\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 22.6276\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 46s 232us/step - loss: 22.4183\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 22.4774\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 22.4629\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 22.1554\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 22.1541\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 22.1479\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 22.2434\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 47s 233us/step - loss: 22.1002\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 22.1505\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 21.9394\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 21.9164\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 21.8653\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 21.8113\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 45s 226us/step - loss: 21.6942\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 21.5987\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 52s 262us/step - loss: 148.3495\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 48s 240us/step - loss: 37.4611\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 48s 240us/step - loss: 32.8077\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 48s 241us/step - loss: 31.7304\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 49s 243us/step - loss: 30.9626\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 48s 239us/step - loss: 30.1759\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 49s 243us/step - loss: 29.4816\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 48s 238us/step - loss: 28.9361\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 48s 238us/step - loss: 28.3730\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 49s 243us/step - loss: 27.9126\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 48s 239us/step - loss: 27.5849\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 48s 240us/step - loss: 27.4884\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 27.1191\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 26.9249\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 26.7045\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 26.5903\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 26.3748\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 48s 240us/step - loss: 26.2088\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 49s 243us/step - loss: 26.0709\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 49s 243us/step - loss: 26.0237\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 48s 240us/step - loss: 25.9074\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 25.7458\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 25.6471\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 25.5768\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 25.4757\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 25.3835\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 25.2726\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 25.2217\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 25.1889\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 24.9986\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 24.9645\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 24.9480\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 24.8903\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 24.7083\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 24.6713\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 48s 238us/step - loss: 24.6410\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 48s 238us/step - loss: 24.5802\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 24.5298\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 24.4913\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 24.4601\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 48s 238us/step - loss: 24.3140\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 24.2397\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 48s 238us/step - loss: 24.1873\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 24.2002\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 24.1474\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 24.1062\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 23.9739\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 23.8949\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 23.8550\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 23.7239\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 51s 257us/step - loss: 31.2664\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 14.4871\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 13.6546\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 13.1161\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 12.4970\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 11.9266\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 11.3973\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 11.0571\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 10.7996\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 10.6159\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 10.3608\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 48s 238us/step - loss: 10.1509\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 9.8989\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 9.6187\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 46s 230us/step - loss: 9.3645\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 9.1055\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 8.9102\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 8.6679\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 47s 237us/step - loss: 8.4561\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 8.1879\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 8.0813\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 7.8700\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 7.7185\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 7.5480\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 7.4795\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 7.4104\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 7.3028\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 7.2246\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 7.1390\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 7.0879\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 7.0480\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 48s 238us/step - loss: 6.9750\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 49s 247us/step - loss: 6.9015\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 49s 247us/step - loss: 6.8572\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 48s 239us/step - loss: 6.7812\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 6.7339\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 47s 235us/step - loss: 6.7110\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 6.6296\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 6.6523\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 6.5602\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 47s 234us/step - loss: 6.5657\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 48s 239us/step - loss: 6.5086\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 48s 241us/step - loss: 6.4450\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 48s 239us/step - loss: 6.4550\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 48s 242us/step - loss: 6.4205\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 48s 239us/step - loss: 6.4248\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 48s 238us/step - loss: 6.4124\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 48s 240us/step - loss: 6.3668\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 49s 245us/step - loss: 6.3269\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 49s 247us/step - loss: 6.3038\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 55s 274us/step - loss: 135.5766\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 49s 247us/step - loss: 37.9046\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 49s 247us/step - loss: 32.5988\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 50s 250us/step - loss: 31.4119\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 50s 249us/step - loss: 30.3639\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 49s 245us/step - loss: 29.5399\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 49s 243us/step - loss: 29.1258\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 48s 242us/step - loss: 28.3475\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 48s 241us/step - loss: 27.6455\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 48s 239us/step - loss: 27.1376\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 48s 239us/step - loss: 26.4781\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 49s 243us/step - loss: 25.8147\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 50s 249us/step - loss: 25.4864\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 50s 251us/step - loss: 25.1281\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 49s 245us/step - loss: 24.7121\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 51s 255us/step - loss: 24.6577\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 50s 249us/step - loss: 24.3591\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 50s 251us/step - loss: 24.2282\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 50s 251us/step - loss: 24.0433\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 49s 247us/step - loss: 23.9846\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 50s 252us/step - loss: 23.7336\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 49s 247us/step - loss: 23.6711\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 49s 243us/step - loss: 23.6296\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 49s 243us/step - loss: 23.4120\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 49s 246us/step - loss: 23.4193\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 48s 242us/step - loss: 23.2119\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 49s 245us/step - loss: 23.1528\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 49s 244us/step - loss: 23.0256\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 48s 242us/step - loss: 22.9823\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 48s 241us/step - loss: 22.8667\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 22.9542\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 48s 240us/step - loss: 22.7960\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 48s 241us/step - loss: 22.8217\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 50s 249us/step - loss: 22.7781\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 50s 248us/step - loss: 22.7035\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 48s 242us/step - loss: 22.6132\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 49s 245us/step - loss: 22.6747\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 50s 250us/step - loss: 22.5410\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 50s 252us/step - loss: 22.4765\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 50s 251us/step - loss: 22.4115\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 50s 250us/step - loss: 22.3617\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 51s 256us/step - loss: 22.3641\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 49s 246us/step - loss: 22.2229\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 50s 252us/step - loss: 22.1551\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 51s 257us/step - loss: 22.0742\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 50s 251us/step - loss: 22.0401\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 50s 251us/step - loss: 22.0681\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 50s 251us/step - loss: 21.9127\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 52s 261us/step - loss: 21.8861\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 52s 260us/step - loss: 21.7780\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 57s 284us/step - loss: 118.1001\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 52s 260us/step - loss: 38.0241\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 52s 258us/step - loss: 33.7031\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 52s 259us/step - loss: 32.2515\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 52s 261us/step - loss: 31.9075\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 52s 259us/step - loss: 31.1186\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 52s 260us/step - loss: 30.6943\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 52s 260us/step - loss: 29.8573\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 52s 259us/step - loss: 29.3837\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 52s 258us/step - loss: 28.7306\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 52s 260us/step - loss: 28.2539\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 52s 260us/step - loss: 27.8809\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 50s 250us/step - loss: 27.3837\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 49s 245us/step - loss: 27.1561\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 49s 243us/step - loss: 26.9067\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 50s 250us/step - loss: 26.6823\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 49s 243us/step - loss: 26.4755\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 26.3946\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 26.2542\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 25.9983\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 48s 238us/step - loss: 25.9152\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 48s 238us/step - loss: 25.7161\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 25.6499\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 25.3962\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 25.2822\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 25.1418\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 25.1707\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 24.9575\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 24.8553\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 24.8646\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 24.7585\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 24.6969\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 24.6871\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 48s 239us/step - loss: 24.5611\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 48s 238us/step - loss: 24.5407\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 24.4984\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 48s 238us/step - loss: 24.3083\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 48s 238us/step - loss: 24.2827\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 24.1681\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 24.1369\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 24.0009\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 47s 236us/step - loss: 23.9511\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 23.9337\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 23.8779\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 23.7298\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 23.6805\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 48s 238us/step - loss: 23.7100\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 23.5910\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 23.5437\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 47s 237us/step - loss: 23.5003\n",
      "Epoch 1/50\n",
      "300000/300000 [==============================] - 76s 254us/step - loss: 93.1739\n",
      "Epoch 2/50\n",
      "300000/300000 [==============================] - 72s 239us/step - loss: 31.9744\n",
      "Epoch 3/50\n",
      "300000/300000 [==============================] - 72s 239us/step - loss: 27.2610\n",
      "Epoch 4/50\n",
      "300000/300000 [==============================] - 72s 239us/step - loss: 25.5917\n",
      "Epoch 5/50\n",
      "300000/300000 [==============================] - 72s 238us/step - loss: 24.9171\n",
      "Epoch 6/50\n",
      "300000/300000 [==============================] - 72s 239us/step - loss: 24.3720\n",
      "Epoch 7/50\n",
      "300000/300000 [==============================] - 72s 239us/step - loss: 23.5984\n",
      "Epoch 8/50\n",
      "300000/300000 [==============================] - 72s 239us/step - loss: 22.9626\n",
      "Epoch 9/50\n",
      "300000/300000 [==============================] - 72s 239us/step - loss: 22.2000\n",
      "Epoch 10/50\n",
      "300000/300000 [==============================] - 72s 239us/step - loss: 21.6191\n",
      "Epoch 11/50\n",
      "300000/300000 [==============================] - 71s 238us/step - loss: 21.1826\n",
      "Epoch 12/50\n",
      "300000/300000 [==============================] - 72s 239us/step - loss: 20.8478\n",
      "Epoch 13/50\n",
      "300000/300000 [==============================] - 72s 239us/step - loss: 20.4182\n",
      "Epoch 14/50\n",
      "300000/300000 [==============================] - 72s 239us/step - loss: 20.1188\n",
      "Epoch 15/50\n",
      "300000/300000 [==============================] - 72s 239us/step - loss: 19.9004\n",
      "Epoch 16/50\n",
      "300000/300000 [==============================] - 72s 240us/step - loss: 19.8424\n",
      "Epoch 17/50\n",
      "300000/300000 [==============================] - 72s 239us/step - loss: 19.6000\n",
      "Epoch 18/50\n",
      "300000/300000 [==============================] - 72s 239us/step - loss: 19.4199\n",
      "Epoch 19/50\n",
      "300000/300000 [==============================] - 72s 239us/step - loss: 19.2516\n",
      "Epoch 20/50\n",
      "300000/300000 [==============================] - 72s 240us/step - loss: 19.0221\n",
      "Epoch 21/50\n",
      "300000/300000 [==============================] - 72s 239us/step - loss: 18.9514\n",
      "Epoch 22/50\n",
      "300000/300000 [==============================] - 72s 239us/step - loss: 18.8721\n",
      "Epoch 23/50\n",
      "300000/300000 [==============================] - 72s 239us/step - loss: 18.7354\n",
      "Epoch 24/50\n",
      "300000/300000 [==============================] - 72s 240us/step - loss: 18.7279\n",
      "Epoch 25/50\n",
      "300000/300000 [==============================] - 72s 240us/step - loss: 18.4801\n",
      "Epoch 26/50\n",
      "300000/300000 [==============================] - 72s 240us/step - loss: 18.4897\n",
      "Epoch 27/50\n",
      "300000/300000 [==============================] - 71s 238us/step - loss: 18.4155\n",
      "Epoch 28/50\n",
      "300000/300000 [==============================] - 72s 239us/step - loss: 18.3131\n",
      "Epoch 29/50\n",
      "300000/300000 [==============================] - 71s 238us/step - loss: 18.3207\n",
      "Epoch 30/50\n",
      "300000/300000 [==============================] - 72s 239us/step - loss: 18.1775\n",
      "Epoch 31/50\n",
      "300000/300000 [==============================] - 72s 238us/step - loss: 18.0944\n",
      "Epoch 32/50\n",
      "300000/300000 [==============================] - 72s 238us/step - loss: 18.0773\n",
      "Epoch 33/50\n",
      "300000/300000 [==============================] - 73s 244us/step - loss: 18.0674\n",
      "Epoch 34/50\n",
      "300000/300000 [==============================] - 73s 242us/step - loss: 17.9202\n",
      "Epoch 35/50\n",
      "300000/300000 [==============================] - 76s 252us/step - loss: 17.8571\n",
      "Epoch 36/50\n",
      "300000/300000 [==============================] - 75s 250us/step - loss: 17.8496\n",
      "Epoch 37/50\n",
      "300000/300000 [==============================] - 76s 254us/step - loss: 17.7680\n",
      "Epoch 38/50\n",
      "300000/300000 [==============================] - 75s 251us/step - loss: 17.8235\n",
      "Epoch 39/50\n",
      "300000/300000 [==============================] - 77s 257us/step - loss: 17.6978\n",
      "Epoch 40/50\n",
      "300000/300000 [==============================] - 76s 253us/step - loss: 17.6830\n",
      "Epoch 41/50\n",
      "300000/300000 [==============================] - 75s 250us/step - loss: 17.6866\n",
      "Epoch 42/50\n",
      "300000/300000 [==============================] - 75s 250us/step - loss: 17.5422\n",
      "Epoch 43/50\n",
      "300000/300000 [==============================] - 74s 248us/step - loss: 17.5254\n",
      "Epoch 44/50\n",
      "300000/300000 [==============================] - 74s 248us/step - loss: 17.4745\n",
      "Epoch 45/50\n",
      "300000/300000 [==============================] - 76s 252us/step - loss: 17.4078\n",
      "Epoch 46/50\n",
      "300000/300000 [==============================] - 72s 240us/step - loss: 17.4697\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000/300000 [==============================] - 74s 248us/step - loss: 17.4053\n",
      "Epoch 48/50\n",
      "300000/300000 [==============================] - 74s 248us/step - loss: 17.3416\n",
      "Epoch 49/50\n",
      "300000/300000 [==============================] - 74s 247us/step - loss: 17.3620\n",
      "Epoch 50/50\n",
      "300000/300000 [==============================] - 74s 248us/step - loss: 17.2599\n"
     ]
    }
   ],
   "source": [
    "model = KerasRegressor(build_fn = model_2_subsampled, epochs = 50)\n",
    "parameters = {'kernel_init_1': ['glorot_normal', 'he_normal'],\n",
    "              'kernel_init_2': ['glorot_normal', 'he_normal'],\n",
    "              'kernel_init_3': ['glorot_normal', 'he_normal']}\n",
    "grid_search = GridSearchCV(model, param_grid = parameters,\n",
    "                           n_jobs = 1, cv = 3, iid = False, scoring = 'neg_mean_squared_error')\n",
    "grid_search.fit(X_subsampled, y_subsampled)\n",
    "grid_search_init_results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "init_best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_kernel_init_1</th>\n",
       "      <th>param_kernel_init_2</th>\n",
       "      <th>param_kernel_init_3</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2162.998483</td>\n",
       "      <td>22.988251</td>\n",
       "      <td>9.443983</td>\n",
       "      <td>0.080097</td>\n",
       "      <td>glorot_normal</td>\n",
       "      <td>glorot_normal</td>\n",
       "      <td>glorot_normal</td>\n",
       "      <td>{'kernel_init_1': 'glorot_normal', 'kernel_ini...</td>\n",
       "      <td>-3678.384330</td>\n",
       "      <td>-10.890664</td>\n",
       "      <td>-534.520635</td>\n",
       "      <td>-1407.931877</td>\n",
       "      <td>1619.621940</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2191.773942</td>\n",
       "      <td>8.513757</td>\n",
       "      <td>9.816837</td>\n",
       "      <td>0.113805</td>\n",
       "      <td>glorot_normal</td>\n",
       "      <td>glorot_normal</td>\n",
       "      <td>he_normal</td>\n",
       "      <td>{'kernel_init_1': 'glorot_normal', 'kernel_ini...</td>\n",
       "      <td>-1530.845387</td>\n",
       "      <td>-13.286260</td>\n",
       "      <td>-651.501891</td>\n",
       "      <td>-731.877846</td>\n",
       "      <td>622.142345</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2209.832535</td>\n",
       "      <td>6.167361</td>\n",
       "      <td>10.051025</td>\n",
       "      <td>0.070929</td>\n",
       "      <td>glorot_normal</td>\n",
       "      <td>he_normal</td>\n",
       "      <td>glorot_normal</td>\n",
       "      <td>{'kernel_init_1': 'glorot_normal', 'kernel_ini...</td>\n",
       "      <td>-1706.669540</td>\n",
       "      <td>-10.113611</td>\n",
       "      <td>-216.029634</td>\n",
       "      <td>-644.270928</td>\n",
       "      <td>755.918188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2254.650646</td>\n",
       "      <td>9.665379</td>\n",
       "      <td>10.786780</td>\n",
       "      <td>0.806877</td>\n",
       "      <td>glorot_normal</td>\n",
       "      <td>he_normal</td>\n",
       "      <td>he_normal</td>\n",
       "      <td>{'kernel_init_1': 'glorot_normal', 'kernel_ini...</td>\n",
       "      <td>-2429.271145</td>\n",
       "      <td>-11.293878</td>\n",
       "      <td>-594.965463</td>\n",
       "      <td>-1011.843495</td>\n",
       "      <td>1030.208389</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2285.935818</td>\n",
       "      <td>5.798310</td>\n",
       "      <td>10.653390</td>\n",
       "      <td>0.096139</td>\n",
       "      <td>he_normal</td>\n",
       "      <td>glorot_normal</td>\n",
       "      <td>glorot_normal</td>\n",
       "      <td>{'kernel_init_1': 'he_normal', 'kernel_init_2'...</td>\n",
       "      <td>-2296.238739</td>\n",
       "      <td>-11.812195</td>\n",
       "      <td>-469.966500</td>\n",
       "      <td>-926.005811</td>\n",
       "      <td>986.789423</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2314.357091</td>\n",
       "      <td>12.038404</td>\n",
       "      <td>11.191944</td>\n",
       "      <td>0.498828</td>\n",
       "      <td>he_normal</td>\n",
       "      <td>glorot_normal</td>\n",
       "      <td>he_normal</td>\n",
       "      <td>{'kernel_init_1': 'he_normal', 'kernel_init_2'...</td>\n",
       "      <td>-2267.145413</td>\n",
       "      <td>-10.518101</td>\n",
       "      <td>-135.236608</td>\n",
       "      <td>-804.300041</td>\n",
       "      <td>1035.640257</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2361.017928</td>\n",
       "      <td>17.498182</td>\n",
       "      <td>12.129472</td>\n",
       "      <td>0.449509</td>\n",
       "      <td>he_normal</td>\n",
       "      <td>he_normal</td>\n",
       "      <td>glorot_normal</td>\n",
       "      <td>{'kernel_init_1': 'he_normal', 'kernel_init_2'...</td>\n",
       "      <td>-1826.922889</td>\n",
       "      <td>-11.855988</td>\n",
       "      <td>-443.769897</td>\n",
       "      <td>-760.849591</td>\n",
       "      <td>774.175524</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2431.642772</td>\n",
       "      <td>42.376000</td>\n",
       "      <td>13.078689</td>\n",
       "      <td>0.793008</td>\n",
       "      <td>he_normal</td>\n",
       "      <td>he_normal</td>\n",
       "      <td>he_normal</td>\n",
       "      <td>{'kernel_init_1': 'he_normal', 'kernel_init_2'...</td>\n",
       "      <td>-2029.001743</td>\n",
       "      <td>-11.227399</td>\n",
       "      <td>-124.495558</td>\n",
       "      <td>-721.574900</td>\n",
       "      <td>925.646128</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0    2162.998483     22.988251         9.443983        0.080097   \n",
       "1    2191.773942      8.513757         9.816837        0.113805   \n",
       "2    2209.832535      6.167361        10.051025        0.070929   \n",
       "3    2254.650646      9.665379        10.786780        0.806877   \n",
       "4    2285.935818      5.798310        10.653390        0.096139   \n",
       "5    2314.357091     12.038404        11.191944        0.498828   \n",
       "6    2361.017928     17.498182        12.129472        0.449509   \n",
       "7    2431.642772     42.376000        13.078689        0.793008   \n",
       "\n",
       "  param_kernel_init_1 param_kernel_init_2 param_kernel_init_3  \\\n",
       "0       glorot_normal       glorot_normal       glorot_normal   \n",
       "1       glorot_normal       glorot_normal           he_normal   \n",
       "2       glorot_normal           he_normal       glorot_normal   \n",
       "3       glorot_normal           he_normal           he_normal   \n",
       "4           he_normal       glorot_normal       glorot_normal   \n",
       "5           he_normal       glorot_normal           he_normal   \n",
       "6           he_normal           he_normal       glorot_normal   \n",
       "7           he_normal           he_normal           he_normal   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'kernel_init_1': 'glorot_normal', 'kernel_ini...       -3678.384330   \n",
       "1  {'kernel_init_1': 'glorot_normal', 'kernel_ini...       -1530.845387   \n",
       "2  {'kernel_init_1': 'glorot_normal', 'kernel_ini...       -1706.669540   \n",
       "3  {'kernel_init_1': 'glorot_normal', 'kernel_ini...       -2429.271145   \n",
       "4  {'kernel_init_1': 'he_normal', 'kernel_init_2'...       -2296.238739   \n",
       "5  {'kernel_init_1': 'he_normal', 'kernel_init_2'...       -2267.145413   \n",
       "6  {'kernel_init_1': 'he_normal', 'kernel_init_2'...       -1826.922889   \n",
       "7  {'kernel_init_1': 'he_normal', 'kernel_init_2'...       -2029.001743   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0         -10.890664        -534.520635     -1407.931877     1619.621940   \n",
       "1         -13.286260        -651.501891      -731.877846      622.142345   \n",
       "2         -10.113611        -216.029634      -644.270928      755.918188   \n",
       "3         -11.293878        -594.965463     -1011.843495     1030.208389   \n",
       "4         -11.812195        -469.966500      -926.005811      986.789423   \n",
       "5         -10.518101        -135.236608      -804.300041     1035.640257   \n",
       "6         -11.855988        -443.769897      -760.849591      774.175524   \n",
       "7         -11.227399        -124.495558      -721.574900      925.646128   \n",
       "\n",
       "   rank_test_score  \n",
       "0                8  \n",
       "1                3  \n",
       "2                1  \n",
       "3                7  \n",
       "4                6  \n",
       "5                5  \n",
       "6                4  \n",
       "7                2  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_init_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Errors much higher than on the complete test set, still large fluctuations between folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random search dropout rade and hidden layer neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel_init_1': 'glorot_normal',\n",
       " 'kernel_init_2': 'he_normal',\n",
       " 'kernel_init_3': 'glorot_normal'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def model_3_subsampled(dropout_rate_1, dropout_rate_2, neurons):\n",
    "    K.backend()\n",
    "    model = Sequential()\n",
    "    \n",
    "    #input layer\n",
    "    model.add(Dense(int(X_subsampled.shape[1]), input_dim = int(X_subsampled.shape[1]),\n",
    "                    kernel_initializer = 'glorot_normal'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(rate = dropout_rate_1))\n",
    "    \n",
    "    #hidden layer\n",
    "    model.add(Dense(neurons, kernel_initializer = 'he_normal'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(rate = dropout_rate_2))\n",
    "\n",
    "    \n",
    "    #output layer\n",
    "    model.add(Dense(1, kernel_initializer = 'glorot_normal'))\n",
    "    adam = optimizers.Adam()\n",
    "    model.compile(loss = 'mean_squared_error', optimizer= adam)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0831 19:01:55.860208 139810756114240 deprecation.py:506] From /home/dionizije/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 57s 286us/step - loss: 44.9044\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 53s 265us/step - loss: 21.9651\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 53s 264us/step - loss: 19.7680\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 53s 263us/step - loss: 18.6230\n",
      "Epoch 5/50\n",
